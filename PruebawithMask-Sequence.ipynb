{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIIC - predecir ozono atmosferico\n",
    "---\n",
    "**Obj:** predecir el ozono atmosférico $O_3$ máximo del dia siguiente, utilizando la información de químicos de los dias anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras,gc,time\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-11-01 01:00:00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-11-01 02:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-11-01 03:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-11-01 04:00:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-11-01 05:00:00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         registered_on   CO   PM10  PM25  NO2  NO  NOX  SO2  WD  RH  TEMP  WS  \\\n",
       "0  1997-11-01 01:00:00  2.7   63.0   NaN  NaN NaN  NaN  6.0 NaN NaN   NaN NaN   \n",
       "1  1997-11-01 02:00:00  2.6   54.0   NaN  NaN NaN  NaN  6.0 NaN NaN   NaN NaN   \n",
       "2  1997-11-01 03:00:00  2.2   53.0   NaN  NaN NaN  NaN  5.0 NaN NaN   NaN NaN   \n",
       "3  1997-11-01 04:00:00  2.5   65.0   NaN  NaN NaN  NaN  5.0 NaN NaN   NaN NaN   \n",
       "4  1997-11-01 05:00:00  2.3  118.0   NaN  NaN NaN  NaN  8.0 NaN NaN   NaN NaN   \n",
       "\n",
       "   HCNM  UVA  UVB   O3  \n",
       "0   NaN  NaN  NaN  1.0  \n",
       "1   NaN  NaN  NaN  1.0  \n",
       "2   NaN  NaN  NaN  1.0  \n",
       "3   NaN  NaN  NaN  1.0  \n",
       "4   NaN  NaN  NaN  1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"../proyecto/datasets/\"\n",
    "df_independencia_verano = pd.read_csv(folder+\"dump-Independencia_2018-04-12_230000-verano.csv\")\n",
    "df_independencia_invierno = pd.read_csv(folder+\"dump-Independencia_2018-04-12_230000-invierno.csv\")\n",
    "\n",
    "df_condes_verano = pd.read_csv(folder+\"dump-Las_Condes_2018-04-12_230000-verano.csv\")\n",
    "df_condes_invierno = pd.read_csv(folder+\"dump-Las_Condes_2018-04-12_230000-invierno.csv\")\n",
    "\n",
    "df_independencia_verano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69390</th>\n",
       "      <td>2016-12-31 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553417</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0400</td>\n",
       "      <td>3.2450</td>\n",
       "      <td>10.28500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.8333</td>\n",
       "      <td>26.6333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69391</th>\n",
       "      <td>2016-12-31 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467584</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.4825</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>7.23250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.3333</td>\n",
       "      <td>26.3167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69392</th>\n",
       "      <td>2016-12-31 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>16.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.4925</td>\n",
       "      <td>2.9975</td>\n",
       "      <td>6.49000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.3333</td>\n",
       "      <td>26.0583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.3033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69393</th>\n",
       "      <td>2016-12-31 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.9050</td>\n",
       "      <td>3.4100</td>\n",
       "      <td>7.31500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.3333</td>\n",
       "      <td>25.1417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.9808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69394</th>\n",
       "      <td>2016-12-31 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.6275</td>\n",
       "      <td>3.1625</td>\n",
       "      <td>9.79001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.8333</td>\n",
       "      <td>24.1750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on  CH4        CO  PM10  PM25     NO2      NO  \\\n",
       "69390  2016-12-31 14:00:00  NaN  0.553417  53.0  24.0  7.0400  3.2450   \n",
       "69391  2016-12-31 15:00:00  NaN  0.467584  22.0  21.0  4.4825  2.7500   \n",
       "69392  2016-12-31 16:00:00  NaN  0.459000  16.5  13.0  3.4925  2.9975   \n",
       "69393  2016-12-31 17:00:00  NaN  0.459000  15.0  14.0  3.9050  3.4100   \n",
       "69394  2016-12-31 18:00:00  NaN  0.450417   NaN   NaN  6.6275  3.1625   \n",
       "\n",
       "            NOX  SO2  WD       RH     TEMP  WS  HCNM  UVA  UVB       O3  \n",
       "69390  10.28500  NaN NaN  41.8333  26.6333 NaN   NaN  NaN  NaN  72.5233  \n",
       "69391   7.23250  NaN NaN  39.3333  26.3167 NaN   NaN  NaN  NaN  58.9725  \n",
       "69392   6.49000  NaN NaN  37.3333  26.0583 NaN   NaN  NaN  NaN  50.3033  \n",
       "69393   7.31500  NaN NaN  36.3333  25.1417 NaN   NaN  NaN  NaN  42.9808  \n",
       "69394   9.79001  NaN NaN  38.8333  24.1750 NaN   NaN  NaN  NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ultimo año como test\n",
    "df_condes_verano_train = df_condes_verano[(df_condes_verano[\"registered_on\"]<\"2017\")]\n",
    "df_condes_invierno_train = df_condes_invierno[(df_condes_invierno[\"registered_on\"]<\"2017\")]\n",
    "df_condes_verano_test = df_condes_verano[df_condes_verano[\"registered_on\"]>=\"2017\"]\n",
    "df_condes_invierno_test = df_condes_invierno[df_condes_invierno[\"registered_on\"]>=\"2017\"]\n",
    "\n",
    "df_condes_verano_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69395</th>\n",
       "      <td>2017-01-03 13:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.834697</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69396</th>\n",
       "      <td>2017-01-03 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.715235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69397</th>\n",
       "      <td>2017-01-03 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.2575</td>\n",
       "      <td>1.7600</td>\n",
       "      <td>12.0175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.9167</td>\n",
       "      <td>28.8167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.537322</td>\n",
       "      <td>73.6176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69398</th>\n",
       "      <td>2017-01-03 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768001</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.8350</td>\n",
       "      <td>2.5025</td>\n",
       "      <td>13.3375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2500</td>\n",
       "      <td>28.2917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.778006</td>\n",
       "      <td>57.6258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69399</th>\n",
       "      <td>2017-01-03 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5775</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>14.1625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>27.4250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.862870</td>\n",
       "      <td>51.9867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on  CH4        CO  PM10  PM25      NO2      NO  \\\n",
       "69395  2017-01-03 13:00:00  NaN       NaN   NaN   NaN      NaN     NaN   \n",
       "69396  2017-01-03 14:00:00  NaN       NaN  19.5  21.0      NaN     NaN   \n",
       "69397  2017-01-03 15:00:00  NaN  0.836667  13.5  18.0  10.2575  1.7600   \n",
       "69398  2017-01-03 16:00:00  NaN  0.768001  19.5   2.0  10.8350  2.5025   \n",
       "69399  2017-01-03 17:00:00  NaN  0.793750  72.0  10.0  11.5775  2.5850   \n",
       "\n",
       "           NOX  SO2  WD       RH     TEMP  WS  HCNM  UVA        UVB       O3  \n",
       "69395      NaN  NaN NaN      NaN      NaN NaN   NaN  0.0  28.834697      NaN  \n",
       "69396      NaN  NaN NaN      NaN      NaN NaN   NaN  0.0  24.715235      NaN  \n",
       "69397  12.0175  NaN NaN  14.9167  28.8167 NaN   NaN  0.0  24.537322  73.6176  \n",
       "69398  13.3375  NaN NaN  12.2500  28.2917 NaN   NaN  0.0  17.778006  57.6258  \n",
       "69399  14.1625  NaN NaN  14.5000  27.4250 NaN   NaN  0.0   9.862870  51.9867  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_condes_verano_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [registered_on, CH4, CO, PM10, PM25, NO2, NO, NOX, SO2, WD, RH, TEMP, WS, HCNM, UVA, UVB, O3]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_condes_verano.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si elimino todas las que tengan al menos un null se eliminan todos los registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows_to_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf4d455d21bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_condes_verano_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrows_to_use\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"O3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(how=\"all\",O3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rows_to_use' is not defined"
     ]
    }
   ],
   "source": [
    "df_condes_verano_train.loc[:,rows_to_use].dropna(subset=[\"O3\"])#(how=\"all\",O3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRe PRocesarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropnan de o3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## representacion\n",
    "rows_to_use = [\"CO\",\"PM10\",\"PM25\",\"NO2\",\"NO\",\"NOX\",\"SO2\",\"WD\",\"RH\",\"TEMP\",\"WS\",\"HCNM\",\"UVA\",\"UVB\",\"O3\"]\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def estadisticos(timesteps):\n",
    "    a_utilizar = [np.nanmax]#,np.nanmin,np.nanstd,np.nanmean]\n",
    "    return np.concatenate([ function(timesteps,axis=0) for function in a_utilizar])\n",
    "\n",
    "def create_sequences(dataframe,lag=1,dia=True):\n",
    "    #preprocesamiento asumiendo dataset es una secuencia\n",
    "    timestep = dataframe.loc[:,\"registered_on\"].values\n",
    "    \n",
    "    indices_orden = []\n",
    "    diax = timestep[0].split(\"-\")[-1].split(\" \")[0]\n",
    "    aux_indices1 = 0\n",
    "    aux_indices2 = 0 \n",
    "    for dato in timestep[1:]:\n",
    "        nuevo_dia = dato.split(\"-\")[-1].split(\" \")[0]\n",
    "        aux_indices2+=1\n",
    "        if diax != nuevo_dia:\n",
    "            diax = nuevo_dia\n",
    "            #if aux_indices2-aux_indices1==24:\n",
    "            #    aux_indices2-=1\n",
    "            indices_orden.append([aux_indices1,aux_indices2])\n",
    "            aux_indices1 = aux_indices2\n",
    "    indices_orden.append([aux_indices1,aux_indices2+1])\n",
    "    data = dataframe.loc[:,rows_to_use].values\n",
    "    data = np.asarray([data[init:finit] for init,finit in indices_orden])\n",
    "    \n",
    "    horas = 24\n",
    "    \n",
    "    dataX = []\n",
    "    dataY =[]\n",
    "    for t_plus_1 in range(lag,len(data)):\n",
    "        #se crea el Y (target)\n",
    "        predecir = data[t_plus_1][:,-1] #todas las ultimas columnas --sequence\n",
    "        dataY.append(predecir)\n",
    "        columnasX = [] #se crea el X (inputs) columnas para predecir Y\n",
    "        for i in np.arange(lag,0,-1): #para los valores anteriores al t_plus_1 durante un lag\n",
    "            columnasX.append( data[t_plus_1-i] )\n",
    "        dataX.append(columnasX)\n",
    "    \n",
    "    #mascara delete..\n",
    "    mask_delete = np.ones(len(dataY),dtype=bool)\n",
    "    if not dia: \n",
    "        for i,dato in enumerate(dataY):\n",
    "            if np.any(np.isnan(dato)): #uno en sequencia---algun nulo\n",
    "                mask_delete[i] = False #eliminar de training\n",
    "    else:\n",
    "        for i,dato in enumerate(dataY):\n",
    "            if np.all(np.isnan(dato)): #todos en sequencia\n",
    "                mask_delete[i] = False #eliminar de training\n",
    "        \n",
    "    if dia: #calcular estadisticos\n",
    "        dataX = [[ estadisticos(timestep) for timestep in datito] for datito in dataX] \n",
    "    else:\n",
    "        aux = [ np.concatenate(datito) for datito in dataX] #junta los lag..\n",
    "        #pad\n",
    "        mask = np.full(len(rows_to_use) , -1.)\n",
    "        dataX = pad_sequences(aux, maxlen=lag*horas, dtype='float32', padding='pre', value=mask) #rellena \n",
    "    dataY = pad_sequences(dataY, maxlen=horas, dtype='object', padding='post', value=np.nan) #rellena \n",
    "    return np.array(dataX)[mask_delete],np.array(dataY)[mask_delete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays shapes\n",
      "Train verano (input):  (950, 48, 15)\n",
      "Train invierno (input):  (967, 48, 15)\n",
      "Train verano (output):  (950, 24)\n",
      "Train invierno (output):  (967, 24)\n"
     ]
    }
   ],
   "source": [
    "lag = 2\n",
    "dia = False #a sequencia\n",
    "trainX1, trainY1 = create_sequences(df_condes_verano_train, lag,dia)\n",
    "trainX2, trainY2 = create_sequences(df_condes_invierno_train, lag,dia)\n",
    "\n",
    "testX1, testY1 = create_sequences(df_condes_verano_test, lag,dia)\n",
    "testX2, testY2 = create_sequences(df_condes_invierno_test, lag,dia)\n",
    "\n",
    "print(\"All arrays shapes\")\n",
    "print(\"Train verano (input): \",trainX1.shape)\n",
    "print(\"Train invierno (input): \",trainX2.shape)\n",
    "print(\"Train verano (output): \",trainY1.shape)\n",
    "print(\"Train invierno (output): \",trainY2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximo calculado\n"
     ]
    }
   ],
   "source": [
    "#o predecir el maximo en etiqueta...\n",
    "trainY1 = np.nanmax(trainY1,axis=1)\n",
    "trainY2 = np.nanmax(trainY2,axis=1)\n",
    "testY1 =  np.nanmax(testY1,axis=1)\n",
    "testY2 =  np.nanmax(testY2,axis=1)\n",
    "print(\"Maximo calculado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trid_to_2d(array,backward=False):\n",
    "    if backward:\n",
    "        return array.reshape(array.shape[0]/lag, lag ,array.shape[-1])\n",
    "    else:\n",
    "        return array.reshape((np.prod(array.shape[:2]), array.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-355a8517d883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrid_to_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrid_to_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "trid_to_2d(trid_to_2d(trainX),backward=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalar datos y transformar para entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 48, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculo de estadisticos (\"fit\") MinMaxScaler\n",
    "class MinMax(object):\n",
    "    def __init__(self,aux=True):\n",
    "        self.minimos = None\n",
    "        self.maximos = None\n",
    "        \n",
    "    def fit(self,data):\n",
    "        self.minimos = np.nanmin(data, axis=(0,1))#, keepdims=True)\n",
    "        self.maximos = np.nanmax(data ,axis=(0,1))#, keepdims=True)\n",
    "    \n",
    "    def transform(self,data):\n",
    "        #normalize between 0 and 1 every statisctic\n",
    "        return (data-self.minimos) / (self.maximos-self.minimos)\n",
    "    \n",
    "    def inverse_transform(self,data):\n",
    "        return data*(self.maximos-self.minimos) + self.minimos\n",
    "    \n",
    "scaler_model1 = MinMax()\n",
    "scaler_model1.fit(trainX1)\n",
    "X_train1 = scaler_model1.transform(trainX1)\n",
    "X_test1 = scaler_model1.transform(testX1)\n",
    "\n",
    "scaler_model2 = MinMax()\n",
    "scaler_model2.fit(trainX2)\n",
    "X_train2 = scaler_model2.transform(trainX2)\n",
    "X_test2 = scaler_model2.transform(testX2)\n",
    "\n",
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimos en train:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Minimos en test:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimos en train: \", np.nanmin(X_train1, axis=(0,1)))\n",
    "print(\"Minimos en test: \", np.nanmin(X_test1, axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximos en train:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Maximos en test:  [0.34242496 0.3527508  0.52879584 0.67041296 0.83688116 0.8192184\n",
      " 0.         0.         0.9509843  0.8743269  0.         0.\n",
      " 0.04304834 0.26231417 0.37820512]\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximos en train: \", np.nanmax(X_train2, axis=(0,1)))\n",
    "print(\"Maximos en test: \", np.nanmax(X_test2, axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mascara agregada\n"
     ]
    }
   ],
   "source": [
    "mask_value = -1.\n",
    "def nan_to_num(data,mask_value):\n",
    "    return np.asarray([[[mask_value if np.isnan(x) else x for x in timestep] for timestep in array] for array in data])\n",
    "\n",
    "X_train1 = nan_to_num(X_train1,mask_value)\n",
    "X_test1 = nan_to_num(X_test1,mask_value)\n",
    "X_train2 = nan_to_num(X_train2,mask_value)\n",
    "X_test2 = nan_to_num(X_test2,mask_value)\n",
    "print(\"Mascara agregada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mascara agregada en etiqueta\n"
     ]
    }
   ],
   "source": [
    "def nan_to_num(data,mask_value):\n",
    "    return np.asarray([[mask_value if np.isnan(x) else x for x in array] for array in data])\n",
    "\n",
    "y_train1 = nan_to_num(trainY1,mask_value)\n",
    "y_test1 = nan_to_num(testY1,mask_value)\n",
    "y_train2 = nan_to_num(trainY2,mask_value)\n",
    "y_test2 = nan_to_num(testY2,mask_value)\n",
    "print(\"Mascara agregada en etiqueta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#para el Y tambien...\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#o standar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler_model = MinMaxScaler()\n",
    "scaler_model = StandardScaler()\n",
    "scaler_model.fit(trainY1)\n",
    "y_train1 = scaler_model.transform(trainY1)\n",
    "y_test1 = scaler_model.transform(testY1)\n",
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características del modelo:\n",
    "* Predecir el máximo de ozono $O_3$ del día siguiente (del período de 24 horas).\n",
    "* Grano de predicción: Horas o día?\n",
    "* Cuanta información anterior utilizar? ..3 dias\n",
    "* Nulos? en $O_3$ o contaminantes?\n",
    "    * Borrar\n",
    "    * Mascara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "opt = 'adam'\n",
    "loss_utilizada = 'mse' #?\n",
    "nhidden = 64\n",
    "from attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, None, 5)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 10)     60          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_1 (Recurre [(None, 10), (None,  840         time_distributed_1[0][0]         \n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8)            88          recurrent_sequential_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_2 (Recurre (None, 8, 8)         848         dense_4[0][0]                    \n",
      "                                                                 recurrent_sequential_1[0][1]     \n",
      "                                                                 recurrent_sequential_1[0][2]     \n",
      "                                                                 dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,836\n",
      "Trainable params: 1,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/farizrahman4u/seq2seq\n",
    "import seq2seq\n",
    "from seq2seq.models import Seq2Seq\n",
    "from seq2seq.models import AttentionSeq2Seq\n",
    "\n",
    "\n",
    "model = Seq2Seq(input_dim=5, hidden_dim=10, output_length=8, output_dim=8)\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_13 (Masking)         (None, 48, 15)            0         \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (None, 48, 64)            15360     \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (None, 48, 64)            24768     \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 48, 1)             65        \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 40,202\n",
      "Trainable params: 40,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_14 (Masking)         (None, 48, 15)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 48, 128)           30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 48, 64)            86400     \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 48, 1)             65        \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 117,194\n",
      "Trainable params: 117,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_422 (InputLayer)          (None, None, 15)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, None, 64)     1024        input_422[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_15 (Recurr [(None, 64), (None,  99072       time_distributed_16[0][0]        \n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 1)            65          recurrent_sequential_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "input_441 (InputLayer)          (None, 24, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_16 (Recurr (None, 24, 1)        50883       dense_255[0][0]                  \n",
      "                                                                 recurrent_sequential_15[0][1]    \n",
      "                                                                 recurrent_sequential_15[0][2]    \n",
      "                                                                 dense_255[0][0]                  \n",
      "                                                                 input_441[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 151,044\n",
      "Trainable params: 151,044\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_175 (Model)            (None, 48, 64)            181761    \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 48, 1)             65        \n",
      "_________________________________________________________________\n",
      "gru_24 (GRU)                 (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 181,835\n",
      "Trainable params: 181,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from seq2seq.models import Seq2Seq,AttentionSeq2Seq\n",
    "\n",
    "timesteps = X_train1.shape[1]\n",
    "features = X_train1.shape[2] #todo excepto o3\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "def attention_multiply(vects):\n",
    "    encoder, attention = vects\n",
    "    return K.batch_dot(attention,encoder, axes=1)\n",
    "\n",
    "def modelo(tipo,dia=True):\n",
    "    regularization = 0.005\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=mask_value, input_shape=(timesteps, features)))\n",
    "\n",
    "    if tipo==\"sin atencion\":\n",
    "        model.add(GRU(nhidden,return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "        model.add(GRU(nhidden,return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "    elif tipo==\"atencion\":\n",
    "        model.add(Bidirectional(GRU(nhidden, return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization))))\n",
    "        model.add(AttentionDecoder(nhidden, nhidden,kernel_regularizer=keras.regularizers.l2(regularization))) #que son esos  (units, output_dim)\n",
    "    \n",
    "    elif tipo==\"sin atencion libreria\":\n",
    "        aux_model = Seq2Seq(teacher_force=True,input_dim=features, hidden_dim=nhidden, output_length=24, output_dim=1,depth=3)\n",
    "        #teacherforse=True\n",
    "        #aux_model = Model(inputs=model.inputs,outputs=aux_model(model.outputs))\n",
    "        \n",
    "        #layer_aux =  GRU(nhidden, return_sequences=False)(aux_model.outputs)\n",
    "        #layer_aux = Dense(1,activation='linear')(layer_aux) #1 prediccion?\n",
    "        \n",
    "        #model = Model(inputs=aux_model.inputs,outputs=layer_aux)\n",
    "        aux_model.compile(loss=loss_utilizada,optimizer=opt)\n",
    "        aux_model.summary()\n",
    "        return aux_model\n",
    "    \n",
    "    elif tipo==\"atencion libreria\":\n",
    "        aux_model = AttentionSeq2Seq(input_dim=features,input_length=timesteps,hidden_dim=nhidden\n",
    "                                     ,output_length=timesteps,output_dim=nhidden,depth=2)\n",
    "        model = Sequential()\n",
    "        model.add(aux_model)\n",
    "    \n",
    "    if dia:\n",
    "        model.add(GRU(nhidden, return_sequences=False,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(regularization))) #1 prediccion?\n",
    "    else:\n",
    "        model.add(TimeDistributed(Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(regularization)))) #varias prediccions--a nivel de horario..\n",
    "        #model.add(GlobalMaxPooling1D()) #no soporta maskin\n",
    "        model.add(GRU(1,return_sequences=False))\n",
    "    \n",
    "    model.compile(loss=loss_utilizada,optimizer=opt)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "modelo1 = modelo(\"sin atencion\",dia)\n",
    "modelo2 = modelo(\"atencion\",dia)\n",
    "modelo3 = modelo(\"sin atencion libreria\",dia)\n",
    "modelo4 = modelo(\"atencion libreria\",dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "2931/2931 [==============================] - 13s 4ms/step - loss: 5583.4554 - val_loss: 3220.1545\n",
      "Epoch 2/20\n",
      "2931/2931 [==============================] - 1s 315us/step - loss: 4336.0182 - val_loss: 2608.2805\n",
      "Epoch 3/20\n",
      "2931/2931 [==============================] - 1s 329us/step - loss: 3654.8928 - val_loss: 2122.1171\n",
      "Epoch 4/20\n",
      "2931/2931 [==============================] - 1s 333us/step - loss: 3083.6249 - val_loss: 1725.8915\n",
      "Epoch 5/20\n",
      "2931/2931 [==============================] - 1s 326us/step - loss: 2606.8954 - val_loss: 1404.9029\n",
      "Epoch 6/20\n",
      "2931/2931 [==============================] - 1s 309us/step - loss: 2201.6552 - val_loss: 1147.0733\n",
      "Epoch 7/20\n",
      "2931/2931 [==============================] - 1s 306us/step - loss: 1884.7589 - val_loss: 946.0074\n",
      "Epoch 8/20\n",
      "2931/2931 [==============================] - 1s 304us/step - loss: 1608.3693 - val_loss: 791.6010\n",
      "Epoch 9/20\n",
      "2931/2931 [==============================] - 1s 314us/step - loss: 1377.2916 - val_loss: 677.2862\n",
      "Epoch 10/20\n",
      "2931/2931 [==============================] - 1s 317us/step - loss: 1204.1290 - val_loss: 595.1383\n",
      "Epoch 11/20\n",
      "2931/2931 [==============================] - 1s 318us/step - loss: 1064.4757 - val_loss: 540.1766\n",
      "Epoch 12/20\n",
      "2931/2931 [==============================] - 1s 319us/step - loss: 952.0002 - val_loss: 506.6342\n",
      "Epoch 13/20\n",
      "2931/2931 [==============================] - 1s 320us/step - loss: 874.4899 - val_loss: 489.7315\n",
      "Epoch 14/20\n",
      "2931/2931 [==============================] - 1s 319us/step - loss: 803.0370 - val_loss: 485.1584\n",
      "Epoch 15/20\n",
      "2931/2931 [==============================] - 1s 320us/step - loss: 751.7063 - val_loss: 489.0904\n",
      "Epoch 16/20\n",
      "2931/2931 [==============================] - 1s 313us/step - loss: 712.1904 - val_loss: 498.8207\n",
      "Epoch 17/20\n",
      "2931/2931 [==============================] - 1s 311us/step - loss: 710.6207 - val_loss: 511.6660\n",
      "Epoch 18/20\n",
      "2931/2931 [==============================] - 1s 320us/step - loss: 670.8582 - val_loss: 525.6414\n",
      "Epoch 19/20\n",
      "2931/2931 [==============================] - 1s 314us/step - loss: 657.6199 - val_loss: 539.9472\n",
      "Epoch 20/20\n",
      "2931/2931 [==============================] - 1s 319us/step - loss: 658.8602 - val_loss: 552.5571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93f0605358>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo1.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 950 samples, validate on 43 samples\n",
      "Epoch 1/20\n",
      "950/950 [==============================] - 20s 21ms/step - loss: 8406.8187 - val_loss: 6237.8115\n",
      "Epoch 2/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8377.3369 - val_loss: 6223.3930\n",
      "Epoch 3/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8361.1848 - val_loss: 6209.8784\n",
      "Epoch 4/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8346.2092 - val_loss: 6197.5575\n",
      "Epoch 5/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8332.6855 - val_loss: 6186.6649\n",
      "Epoch 6/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8320.8717 - val_loss: 6177.2271\n",
      "Epoch 7/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8310.7392 - val_loss: 6169.2814\n",
      "Epoch 8/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8302.2670 - val_loss: 6162.6480\n",
      "Epoch 9/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8295.2572 - val_loss: 6157.1973\n",
      "Epoch 10/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8289.4917 - val_loss: 6152.7745\n",
      "Epoch 11/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8284.8140 - val_loss: 6149.1137\n",
      "Epoch 12/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8280.9756 - val_loss: 6146.1335\n",
      "Epoch 13/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8277.8281 - val_loss: 6143.7048\n",
      "Epoch 14/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8275.2502 - val_loss: 6141.6828\n",
      "Epoch 15/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8273.1118 - val_loss: 6140.0045\n",
      "Epoch 16/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8271.3271 - val_loss: 6138.6041\n",
      "Epoch 17/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8269.8320 - val_loss: 6137.4277\n",
      "Epoch 18/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8268.5729 - val_loss: 6136.4231\n",
      "Epoch 19/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8267.4960 - val_loss: 6135.5745\n",
      "Epoch 20/20\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 8266.5773 - val_loss: 6134.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcfcb266a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_trainy = y_train1.reshape(y_train1.shape[0],y_train1.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "950/950 [==============================] - 24s 25ms/step - loss: 1604.5005\n",
      "Epoch 2/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.3703\n",
      "Epoch 3/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.3064\n",
      "Epoch 4/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.3000\n",
      "Epoch 5/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2947\n",
      "Epoch 6/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2899\n",
      "Epoch 7/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2855\n",
      "Epoch 8/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2810\n",
      "Epoch 9/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2768\n",
      "Epoch 10/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2727\n",
      "Epoch 11/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2686\n",
      "Epoch 12/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2646\n",
      "Epoch 13/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2607\n",
      "Epoch 14/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2570\n",
      "Epoch 15/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2535\n",
      "Epoch 16/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2499\n",
      "Epoch 17/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2467\n",
      "Epoch 18/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2439\n",
      "Epoch 19/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2414\n",
      "Epoch 20/20\n",
      "950/950 [==============================] - 13s 13ms/step - loss: 1585.2391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcde5809d30>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo3.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))\n",
    "modelo3.fit([X_train1,aux_trainy], aux_trainy, epochs=epochs, batch_size=batch_size)# validation_split=0.2)#validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probar= modelo3.predict(X_train1)\n",
    "probar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/15\n",
      "2931/2931 [==============================] - 13s 4ms/step - loss: 5641.3066 - val_loss: 3279.1513\n",
      "Epoch 2/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 4395.8773 - val_loss: 2658.1465\n",
      "Epoch 3/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 3699.4842 - val_loss: 2159.9836\n",
      "Epoch 4/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 3119.7706 - val_loss: 1755.7045\n",
      "Epoch 5/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 2632.7764 - val_loss: 1427.1046\n",
      "Epoch 6/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 2224.0965 - val_loss: 1164.2534\n",
      "Epoch 7/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1883.1651 - val_loss: 957.8679\n",
      "Epoch 8/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1602.1872 - val_loss: 798.1491\n",
      "Epoch 9/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1372.0597 - val_loss: 681.4103\n",
      "Epoch 10/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1186.4264 - val_loss: 596.6783\n",
      "Epoch 11/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1038.5359 - val_loss: 540.3697\n",
      "Epoch 12/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 922.7308 - val_loss: 505.7938\n",
      "Epoch 13/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 833.2775 - val_loss: 488.4626\n",
      "Epoch 14/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 765.7111 - val_loss: 483.9621\n",
      "Epoch 15/15\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 715.2201 - val_loss: 488.3781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa651460400>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo4.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seguir con modelo 3 y modelo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#ivnierno\n",
    "modelo1.fit(X_train2, trainY2, epochs=epochs, batch_size=batch_size, validation_data=(X_test2, testY2))\n",
    "modelo2.fit(X_train2, trainY2, epochs=epochs, batch_size=batch_size, validation_data=(X_test2, testY2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `rmse` not found.\n"
     ]
    }
   ],
   "source": [
    "## evaluación?\n",
    "rmse?\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse_evaluation(model,input_data,output_data):\n",
    "    predict = model.predict(input_data)\n",
    "    #recover data\n",
    "    predict = scaler_model.inverse_transform(predict)\n",
    "    output_data = scaler_model.inverse_transform(output_data)\n",
    "    print(\"RMSE del modelo en test: \",np.sqrt(mean_squared_error(output_data,predict)))\n",
    "    return \n",
    "\n",
    "def evaluar_modelo(modelito,data):\n",
    "    mse_test = modelito.evaluate(data[0],data[1])\n",
    "    print(\"RMSE del modelo en test: \",np.sqrt(mse_test))\n",
    "    return np.sqrt(mse_test)\n",
    "#if es hora.. max\n",
    "# si es por dia ya predice max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 291us/step\n",
      "RMSE del modelo en test:  23.506534082171495\n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(modelo1,[X_test1,testY1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo en test:  25.499195690214826\n"
     ]
    }
   ],
   "source": [
    "rmse_evaluation(modelo2,X_test1,y_test1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 390us/step\n",
      "RMSE del modelo en test:  72.43425606591757\n"
     ]
    }
   ],
   "source": [
    "evaluar_modelo(modelo2,[X_test1,testY1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenar 1 modelo por cada conjunto y promediar o entrenar juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_67 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_161 (GRU)                (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_68 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_163 (GRU)                (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "2931/2931 [==============================] - 17s 6ms/step - loss: 6155.9501 - val_loss: 3121.1954\n",
      "Epoch 2/20\n",
      "2931/2931 [==============================] - 1s 464us/step - loss: 4127.6794 - val_loss: 2406.3880\n",
      "Epoch 3/20\n",
      "2931/2931 [==============================] - 1s 491us/step - loss: 3381.1038 - val_loss: 1908.5063\n",
      "Epoch 4/20\n",
      "2931/2931 [==============================] - 1s 496us/step - loss: 2799.2026 - val_loss: 1524.8742\n",
      "Epoch 5/20\n",
      "2931/2931 [==============================] - 1s 491us/step - loss: 2348.0240 - val_loss: 1225.7524\n",
      "Epoch 6/20\n",
      "2931/2931 [==============================] - 1s 475us/step - loss: 1965.6158 - val_loss: 994.2796\n",
      "Epoch 7/20\n",
      "2931/2931 [==============================] - 1s 485us/step - loss: 1660.5214 - val_loss: 819.5310\n",
      "Epoch 8/20\n",
      "2931/2931 [==============================] - 1s 467us/step - loss: 1408.2978 - val_loss: 693.0456\n",
      "Epoch 9/20\n",
      "2931/2931 [==============================] - 1s 493us/step - loss: 1223.7780 - val_loss: 602.1245\n",
      "Epoch 10/20\n",
      "2931/2931 [==============================] - 1s 494us/step - loss: 1066.9246 - val_loss: 542.6654\n",
      "Epoch 11/20\n",
      "2931/2931 [==============================] - 1s 473us/step - loss: 940.0842 - val_loss: 506.6292\n",
      "Epoch 12/20\n",
      "2931/2931 [==============================] - 1s 471us/step - loss: 861.0803 - val_loss: 489.1559\n",
      "Epoch 13/20\n",
      "2931/2931 [==============================] - 1s 489us/step - loss: 795.9755 - val_loss: 484.7524\n",
      "Epoch 14/20\n",
      "2931/2931 [==============================] - 1s 487us/step - loss: 746.5207 - val_loss: 489.3890\n",
      "Epoch 15/20\n",
      "2931/2931 [==============================] - 1s 480us/step - loss: 710.6285 - val_loss: 499.9266\n",
      "Epoch 16/20\n",
      "2931/2931 [==============================] - 1s 485us/step - loss: 697.5514 - val_loss: 514.1757\n",
      "Epoch 17/20\n",
      "2931/2931 [==============================] - 1s 470us/step - loss: 665.0456 - val_loss: 529.3576\n",
      "Epoch 18/20\n",
      "2931/2931 [==============================] - 1s 468us/step - loss: 658.4426 - val_loss: 544.9145\n",
      "Epoch 19/20\n",
      "2931/2931 [==============================] - 2s 515us/step - loss: 658.9600 - val_loss: 557.4854\n",
      "Epoch 20/20\n",
      "2931/2931 [==============================] - 1s 481us/step - loss: 644.9292 - val_loss: 575.6131\n",
      "Train on 2401 samples, validate on 116 samples\n",
      "Epoch 1/20\n",
      "2401/2401 [==============================] - 17s 7ms/step - loss: 1065.1766 - val_loss: 87.9969\n",
      "Epoch 2/20\n",
      "2401/2401 [==============================] - 1s 500us/step - loss: 556.5330 - val_loss: 89.9402\n",
      "Epoch 3/20\n",
      "2401/2401 [==============================] - 1s 493us/step - loss: 484.2206 - val_loss: 117.3592\n",
      "Epoch 4/20\n",
      "2401/2401 [==============================] - 1s 466us/step - loss: 455.3539 - val_loss: 144.5604\n",
      "Epoch 5/20\n",
      "2401/2401 [==============================] - 1s 538us/step - loss: 445.3031 - val_loss: 167.0379\n",
      "Epoch 6/20\n",
      "2401/2401 [==============================] - 1s 469us/step - loss: 442.3183 - val_loss: 185.1103\n",
      "Epoch 7/20\n",
      "2401/2401 [==============================] - 1s 552us/step - loss: 440.8813 - val_loss: 196.4110\n",
      "Epoch 8/20\n",
      "2401/2401 [==============================] - 1s 519us/step - loss: 438.1845 - val_loss: 199.8050\n",
      "Epoch 9/20\n",
      "2401/2401 [==============================] - 1s 536us/step - loss: 422.3705 - val_loss: 156.8153\n",
      "Epoch 10/20\n",
      "2401/2401 [==============================] - 1s 498us/step - loss: 384.1452 - val_loss: 190.8879\n",
      "Epoch 11/20\n",
      "2401/2401 [==============================] - 1s 501us/step - loss: 370.6722 - val_loss: 260.6067\n",
      "Epoch 12/20\n",
      "2401/2401 [==============================] - 1s 523us/step - loss: 354.7258 - val_loss: 281.8870\n",
      "Epoch 13/20\n",
      "2401/2401 [==============================] - 1s 486us/step - loss: 349.7132 - val_loss: 315.4710\n",
      "Epoch 14/20\n",
      "2401/2401 [==============================] - 1s 485us/step - loss: 350.3784 - val_loss: 321.3379\n",
      "Epoch 15/20\n",
      "2401/2401 [==============================] - 1s 504us/step - loss: 342.5153 - val_loss: 376.1406\n",
      "Epoch 16/20\n",
      "2401/2401 [==============================] - 1s 483us/step - loss: 346.0013 - val_loss: 383.5395\n",
      "Epoch 17/20\n",
      "2401/2401 [==============================] - 1s 471us/step - loss: 340.7054 - val_loss: 391.4855\n",
      "Epoch 18/20\n",
      "2401/2401 [==============================] - 1s 501us/step - loss: 340.4693 - val_loss: 360.5254\n",
      "Epoch 19/20\n",
      "2401/2401 [==============================] - 1s 550us/step - loss: 339.5296 - val_loss: 426.8820\n",
      "Epoch 20/20\n",
      "2401/2401 [==============================] - 1s 525us/step - loss: 337.0061 - val_loss: 436.8329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93e20011d0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mejor modelo atencion normal\n",
    "modelo_v = modelo(\"atencion\",dia)\n",
    "modelo_i = modelo(\"atencion\",dia)\n",
    "modelo_v.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))\n",
    "modelo_i.fit(X_train2, trainY2, epochs=epochs, batch_size=batch_size, validation_data=(X_test2, testY2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 371us/step\n",
      "RMSE del modelo en test:  23.991938999518787\n",
      "116/116 [==============================] - 0s 340us/step\n",
      "RMSE del modelo en test:  20.900546881842484\n",
      "En promedio este modelo da:  22.446242940680634\n"
     ]
    }
   ],
   "source": [
    "rmse_1 = evaluar_modelo(modelo_v,[X_test1,testY1])    \n",
    "rmse_2 = evaluar_modelo(modelo_i,[X_test2,testY2])    \n",
    "print(\"En promedio este modelo da: \",np.mean([rmse_1,rmse_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo en test:  22.86701676641055\n"
     ]
    }
   ],
   "source": [
    "## evaluación?\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predict1 = modelo_v.predict(X_test1)\n",
    "predict2 = modelo_i.predict(X_test2)\n",
    "\n",
    "print(\"RMSE del modelo en test: \",np.sqrt(mean_squared_error(y_new_test,np.concatenate((predict1,predict2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2004, 69, 15)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack invierno y verano\n",
    "X_new_train = np.concatenate((X_train1,X_train2))\n",
    "X_new_test = np.concatenate((X_test1,X_test2))\n",
    "y_new_train = np.concatenate((trainY1,trainY2))\n",
    "y_new_test = np.concatenate((testY1,testY2))\n",
    "X_new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_70 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_167 (GRU)                (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5332 samples, validate on 311 samples\n",
      "Epoch 1/30\n",
      "5332/5332 [==============================] - 20s 4ms/step - loss: 3231.5229 - val_loss: 1614.2138\n",
      "Epoch 2/30\n",
      "5332/5332 [==============================] - 2s 439us/step - loss: 2011.0821 - val_loss: 1204.3134\n",
      "Epoch 3/30\n",
      "5332/5332 [==============================] - 2s 446us/step - loss: 1604.7259 - val_loss: 1021.5790\n",
      "Epoch 4/30\n",
      "5332/5332 [==============================] - 2s 447us/step - loss: 1381.4656 - val_loss: 956.7702\n",
      "Epoch 5/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 1279.0124 - val_loss: 948.9930\n",
      "Epoch 6/30\n",
      "5332/5332 [==============================] - 2s 439us/step - loss: 1236.8386 - val_loss: 961.4927\n",
      "Epoch 7/30\n",
      "5332/5332 [==============================] - 2s 442us/step - loss: 943.4692 - val_loss: 750.2730\n",
      "Epoch 8/30\n",
      "5332/5332 [==============================] - 2s 435us/step - loss: 741.6348 - val_loss: 793.9720\n",
      "Epoch 9/30\n",
      "5332/5332 [==============================] - 2s 445us/step - loss: 675.7203 - val_loss: 844.4862\n",
      "Epoch 10/30\n",
      "5332/5332 [==============================] - 2s 434us/step - loss: 638.7575 - val_loss: 877.5254\n",
      "Epoch 11/30\n",
      "5332/5332 [==============================] - 2s 440us/step - loss: 585.7677 - val_loss: 329.0120\n",
      "Epoch 12/30\n",
      "5332/5332 [==============================] - 2s 436us/step - loss: 554.6878 - val_loss: 308.7417\n",
      "Epoch 13/30\n",
      "5332/5332 [==============================] - 2s 443us/step - loss: 538.6018 - val_loss: 359.2524\n",
      "Epoch 14/30\n",
      "5332/5332 [==============================] - 2s 437us/step - loss: 513.6801 - val_loss: 298.4245\n",
      "Epoch 15/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 461.3325 - val_loss: 262.1252\n",
      "Epoch 16/30\n",
      "5332/5332 [==============================] - 2s 437us/step - loss: 437.5478 - val_loss: 332.5225\n",
      "Epoch 17/30\n",
      "5332/5332 [==============================] - 2s 438us/step - loss: 429.6047 - val_loss: 286.2611\n",
      "Epoch 18/30\n",
      "5332/5332 [==============================] - 2s 435us/step - loss: 422.7401 - val_loss: 269.3060\n",
      "Epoch 19/30\n",
      "5332/5332 [==============================] - 2s 443us/step - loss: 427.6611 - val_loss: 283.0325\n",
      "Epoch 20/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 411.7659 - val_loss: 334.4499\n",
      "Epoch 21/30\n",
      "5332/5332 [==============================] - 2s 443us/step - loss: 410.3335 - val_loss: 316.4678\n",
      "Epoch 22/30\n",
      "5332/5332 [==============================] - 2s 440us/step - loss: 403.8675 - val_loss: 314.8837\n",
      "Epoch 23/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 402.9730 - val_loss: 273.2212\n",
      "Epoch 24/30\n",
      "5332/5332 [==============================] - 2s 445us/step - loss: 401.2417 - val_loss: 276.7344\n",
      "Epoch 25/30\n",
      "5332/5332 [==============================] - 2s 440us/step - loss: 395.2509 - val_loss: 284.7889\n",
      "Epoch 26/30\n",
      "5332/5332 [==============================] - 2s 439us/step - loss: 396.6369 - val_loss: 299.1025\n",
      "Epoch 27/30\n",
      "5332/5332 [==============================] - 2s 433us/step - loss: 390.9890 - val_loss: 292.2640\n",
      "Epoch 28/30\n",
      "5332/5332 [==============================] - 2s 433us/step - loss: 397.4213 - val_loss: 280.1842\n",
      "Epoch 29/30\n",
      "5332/5332 [==============================] - 2s 436us/step - loss: 389.6017 - val_loss: 293.4558\n",
      "Epoch 30/30\n",
      "5332/5332 [==============================] - 2s 444us/step - loss: 388.4626 - val_loss: 295.8303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93c824ca90>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2_both = modelo(\"atencion\",dia)\n",
    "modelo2_both.fit(X_new_train, y_new_train, epochs=25, batch_size=batch_size, validation_data=(X_new_test, y_new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 0s 344us/step\n",
      "RMSE del modelo en test:  17.199719013374132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.199719013374132"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2_both,[X_new_test,y_new_test])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados: Entrenar un mismo modelo en invierno y verano es mejor..\n",
    "### Conclusiones: Los patrones relacionados con la tarea asignada se repiten/son compartidos en ambos conjuntos\n",
    "\n",
    "## Mejorar\n",
    "---\n",
    "* seguir con atención\n",
    "* Probar predecir secuencia completa (horas)---otro archivo\n",
    "* juntar con independencia???\n",
    "* aumentar lag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independencia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
