{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIIC - predecir ozono atmosferico\n",
    "---\n",
    "**Obj:** predecir el ozono atmosférico $O_3$ máximo del dia siguiente, utilizando la información de químicos de los dias anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras,gc,time\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-11-01 01:00:00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-11-01 02:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-11-01 03:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-11-01 04:00:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-11-01 05:00:00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         registered_on   CO   PM10  PM25  NO2  NO  NOX  SO2  WD  RH  TEMP  WS  \\\n",
       "0  1997-11-01 01:00:00  2.7   63.0   NaN  NaN NaN  NaN  6.0 NaN NaN   NaN NaN   \n",
       "1  1997-11-01 02:00:00  2.6   54.0   NaN  NaN NaN  NaN  6.0 NaN NaN   NaN NaN   \n",
       "2  1997-11-01 03:00:00  2.2   53.0   NaN  NaN NaN  NaN  5.0 NaN NaN   NaN NaN   \n",
       "3  1997-11-01 04:00:00  2.5   65.0   NaN  NaN NaN  NaN  5.0 NaN NaN   NaN NaN   \n",
       "4  1997-11-01 05:00:00  2.3  118.0   NaN  NaN NaN  NaN  8.0 NaN NaN   NaN NaN   \n",
       "\n",
       "   HCNM  UVA  UVB   O3  \n",
       "0   NaN  NaN  NaN  1.0  \n",
       "1   NaN  NaN  NaN  1.0  \n",
       "2   NaN  NaN  NaN  1.0  \n",
       "3   NaN  NaN  NaN  1.0  \n",
       "4   NaN  NaN  NaN  1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"../proyecto/datasets/\"\n",
    "df_independencia_verano = pd.read_csv(folder+\"dump-Independencia_2018-04-12_230000-verano.csv\")\n",
    "df_independencia_invierno = pd.read_csv(folder+\"dump-Independencia_2018-04-12_230000-invierno.csv\")\n",
    "\n",
    "df_condes_verano = pd.read_csv(folder+\"dump-Las_Condes_2018-04-12_230000-verano.csv\")\n",
    "df_condes_invierno = pd.read_csv(folder+\"dump-Las_Condes_2018-04-12_230000-invierno.csv\")\n",
    "\n",
    "df_independencia_verano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69390</th>\n",
       "      <td>2016-12-31 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553417</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0400</td>\n",
       "      <td>3.2450</td>\n",
       "      <td>10.28500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.8333</td>\n",
       "      <td>26.6333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69391</th>\n",
       "      <td>2016-12-31 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467584</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.4825</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>7.23250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.3333</td>\n",
       "      <td>26.3167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69392</th>\n",
       "      <td>2016-12-31 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>16.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.4925</td>\n",
       "      <td>2.9975</td>\n",
       "      <td>6.49000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.3333</td>\n",
       "      <td>26.0583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.3033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69393</th>\n",
       "      <td>2016-12-31 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.9050</td>\n",
       "      <td>3.4100</td>\n",
       "      <td>7.31500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.3333</td>\n",
       "      <td>25.1417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.9808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69394</th>\n",
       "      <td>2016-12-31 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.6275</td>\n",
       "      <td>3.1625</td>\n",
       "      <td>9.79001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.8333</td>\n",
       "      <td>24.1750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on  CH4        CO  PM10  PM25     NO2      NO  \\\n",
       "69390  2016-12-31 14:00:00  NaN  0.553417  53.0  24.0  7.0400  3.2450   \n",
       "69391  2016-12-31 15:00:00  NaN  0.467584  22.0  21.0  4.4825  2.7500   \n",
       "69392  2016-12-31 16:00:00  NaN  0.459000  16.5  13.0  3.4925  2.9975   \n",
       "69393  2016-12-31 17:00:00  NaN  0.459000  15.0  14.0  3.9050  3.4100   \n",
       "69394  2016-12-31 18:00:00  NaN  0.450417   NaN   NaN  6.6275  3.1625   \n",
       "\n",
       "            NOX  SO2  WD       RH     TEMP  WS  HCNM  UVA  UVB       O3  \n",
       "69390  10.28500  NaN NaN  41.8333  26.6333 NaN   NaN  NaN  NaN  72.5233  \n",
       "69391   7.23250  NaN NaN  39.3333  26.3167 NaN   NaN  NaN  NaN  58.9725  \n",
       "69392   6.49000  NaN NaN  37.3333  26.0583 NaN   NaN  NaN  NaN  50.3033  \n",
       "69393   7.31500  NaN NaN  36.3333  25.1417 NaN   NaN  NaN  NaN  42.9808  \n",
       "69394   9.79001  NaN NaN  38.8333  24.1750 NaN   NaN  NaN  NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ultimo año como test\n",
    "df_condes_verano_train = df_condes_verano[(df_condes_verano[\"registered_on\"]<\"2017\")]\n",
    "df_condes_invierno_train = df_condes_invierno[(df_condes_invierno[\"registered_on\"]<\"2017\")]\n",
    "df_condes_verano_test = df_condes_verano[df_condes_verano[\"registered_on\"]>=\"2017\"]\n",
    "df_condes_invierno_test = df_condes_invierno[df_condes_invierno[\"registered_on\"]>=\"2017\"]\n",
    "\n",
    "df_condes_verano_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69395</th>\n",
       "      <td>2017-01-03 13:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.834697</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69396</th>\n",
       "      <td>2017-01-03 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.715235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69397</th>\n",
       "      <td>2017-01-03 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.2575</td>\n",
       "      <td>1.7600</td>\n",
       "      <td>12.0175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.9167</td>\n",
       "      <td>28.8167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.537322</td>\n",
       "      <td>73.6176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69398</th>\n",
       "      <td>2017-01-03 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768001</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.8350</td>\n",
       "      <td>2.5025</td>\n",
       "      <td>13.3375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2500</td>\n",
       "      <td>28.2917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.778006</td>\n",
       "      <td>57.6258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69399</th>\n",
       "      <td>2017-01-03 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5775</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>14.1625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>27.4250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.862870</td>\n",
       "      <td>51.9867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on  CH4        CO  PM10  PM25      NO2      NO  \\\n",
       "69395  2017-01-03 13:00:00  NaN       NaN   NaN   NaN      NaN     NaN   \n",
       "69396  2017-01-03 14:00:00  NaN       NaN  19.5  21.0      NaN     NaN   \n",
       "69397  2017-01-03 15:00:00  NaN  0.836667  13.5  18.0  10.2575  1.7600   \n",
       "69398  2017-01-03 16:00:00  NaN  0.768001  19.5   2.0  10.8350  2.5025   \n",
       "69399  2017-01-03 17:00:00  NaN  0.793750  72.0  10.0  11.5775  2.5850   \n",
       "\n",
       "           NOX  SO2  WD       RH     TEMP  WS  HCNM  UVA        UVB       O3  \n",
       "69395      NaN  NaN NaN      NaN      NaN NaN   NaN  0.0  28.834697      NaN  \n",
       "69396      NaN  NaN NaN      NaN      NaN NaN   NaN  0.0  24.715235      NaN  \n",
       "69397  12.0175  NaN NaN  14.9167  28.8167 NaN   NaN  0.0  24.537322  73.6176  \n",
       "69398  13.3375  NaN NaN  12.2500  28.2917 NaN   NaN  0.0  17.778006  57.6258  \n",
       "69399  14.1625  NaN NaN  14.5000  27.4250 NaN   NaN  0.0   9.862870  51.9867  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_condes_verano_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [registered_on, CH4, CO, PM10, PM25, NO2, NO, NOX, SO2, WD, RH, TEMP, WS, HCNM, UVA, UVB, O3]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_condes_verano.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si elimino todas las que tengan al menos un null se eliminan todos los registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows_to_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf4d455d21bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_condes_verano_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrows_to_use\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"O3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(how=\"all\",O3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rows_to_use' is not defined"
     ]
    }
   ],
   "source": [
    "df_condes_verano_train.loc[:,rows_to_use].dropna(subset=[\"O3\"])#(how=\"all\",O3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRe PRocesarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## representacion\n",
    "rows_to_use = [\"CO\",\"PM10\",\"PM25\",\"NO2\",\"NO\",\"NOX\",\"SO2\",\"WD\",\"RH\",\"TEMP\",\"WS\",\"HCNM\",\"UVA\",\"UVB\",\"O3\"]\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def estadisticos(timesteps):\n",
    "    a_utilizar = [np.nanmax]#,np.nanmin,np.nanstd,np.nanmean]\n",
    "    return np.concatenate([ function(timesteps,axis=0) for function in a_utilizar])\n",
    "\n",
    "def create_sequences(dataframe,lag=1,dia=True):\n",
    "    #preprocesamiento asumiendo dataset es una secuencia\n",
    "    timestep = dataframe.loc[:,\"registered_on\"].values\n",
    "    \n",
    "    indices_orden = []\n",
    "    diax = timestep[0].split(\"-\")[-1].split(\" \")[0]\n",
    "    aux_indices1 = 0\n",
    "    aux_indices2 = 0 \n",
    "    for dato in timestep[1:]:\n",
    "        nuevo_dia = dato.split(\"-\")[-1].split(\" \")[0]\n",
    "        aux_indices2+=1\n",
    "        if diax != nuevo_dia:\n",
    "            diax = nuevo_dia\n",
    "            #if aux_indices2-aux_indices1==24:\n",
    "            #    aux_indices2-=1\n",
    "            indices_orden.append([aux_indices1,aux_indices2])\n",
    "            aux_indices1 = aux_indices2\n",
    "    indices_orden.append([aux_indices1,aux_indices2+1])\n",
    "    data = dataframe.loc[:,rows_to_use].values\n",
    "    data = np.asarray([data[init:finit] for init,finit in indices_orden])\n",
    "    \n",
    "    horas = 24\n",
    "    \n",
    "    dataX = []\n",
    "    dataY =[]\n",
    "    for t_plus_1 in range(lag,len(data)):\n",
    "        #se crea el Y (target)\n",
    "        predecir = data[t_plus_1][:,-1] #todas las ultimas columnas --sequence\n",
    "        dataY.append(predecir)\n",
    "        columnasX = [] #se crea el X (inputs) columnas para predecir Y\n",
    "        for i in np.arange(lag,0,-1): #para los valores anteriores al t_plus_1 durante un lag\n",
    "            columnasX.append( data[t_plus_1-i] )\n",
    "        dataX.append(columnasX)\n",
    "    \n",
    "    #mascara delete..\n",
    "    mask_delete = np.ones(len(dataY),dtype=bool)\n",
    "    if not dia: \n",
    "        for i,dato in enumerate(dataY):\n",
    "            if np.any(np.isnan(dato)): #uno en sequencia---algun nulo\n",
    "                mask_delete[i] = False #eliminar de training\n",
    "    else:\n",
    "        for i,dato in enumerate(dataY):\n",
    "            if np.all(np.isnan(dato)): #todos en sequencia\n",
    "                mask_delete[i] = False #eliminar de training\n",
    "        \n",
    "    if dia: #calcular estadisticos\n",
    "        dataX = [[ estadisticos(timestep) for timestep in datito] for datito in dataX] \n",
    "    else:\n",
    "        aux = [ np.concatenate(datito) for datito in dataX] #junta los lag..\n",
    "        #pad\n",
    "        mask = np.full(len(rows_to_use) , -1.)\n",
    "        dataX = pad_sequences(aux, maxlen=lag*horas, dtype='float32', padding='pre', value=mask) #rellena \n",
    "    dataY = pad_sequences(dataY, maxlen=horas, dtype='object', padding='post', value=np.nan) #rellena \n",
    "    return np.array(dataX)[mask_delete],np.array(dataY)[mask_delete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: All-NaN slice encountered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays shapes\n",
      "Train verano (input):  (2932, 2, 15)\n",
      "Train invierno (input):  (2402, 2, 15)\n",
      "Train verano (output):  (2932, 24)\n",
      "Train invierno (output):  (2402, 24)\n"
     ]
    }
   ],
   "source": [
    "lag = 4\n",
    "dia=True\n",
    "trainX1_cond, trainY1_cond = create_sequences(df_condes_verano_train, lag,dia)\n",
    "trainX2_cond, trainY2_cond = create_sequences(df_condes_invierno_train, lag,dia)\n",
    "\n",
    "testX1_cond, testY1_cond = create_sequences(df_condes_verano_test, lag,dia)\n",
    "testX2_cond, testY2_cond = create_sequences(df_condes_invierno_test, lag,dia)\n",
    "\n",
    "print(\"All arrays shapes\")\n",
    "print(\"Train verano (input): \",trainX1_cond.shape)\n",
    "print(\"Train invierno (input): \",trainX2_cond.shape)\n",
    "print(\"Train verano (output): \",trainY1_cond.shape)\n",
    "print(\"Train invierno (output): \",trainY2_cond.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximo calculado\n"
     ]
    }
   ],
   "source": [
    "#o predecir el maximo en etiqueta...\n",
    "trainY1_cond = np.nanmax(trainY1_cond,axis=1)\n",
    "trainY2_cond = np.nanmax(trainY2_cond,axis=1)\n",
    "testY1_cond =  np.nanmax(testY1_cond,axis=1)\n",
    "testY2_cond =  np.nanmax(testY2_cond,axis=1)\n",
    "print(\"Maximo calculado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trid_to_2d(array,backward=False):\n",
    "    if backward:\n",
    "        return array.reshape(array.shape[0]/lag, lag ,array.shape[-1])\n",
    "    else:\n",
    "        return array.reshape((np.prod(array.shape[:2]), array.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-355a8517d883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrid_to_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrid_to_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "trid_to_2d(trid_to_2d(trainX),backward=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalar datos y transformar para entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2932, 2, 15)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculo de estadisticos (\"fit\") MinMaxScaler\n",
    "class MinMax(object):\n",
    "    def __init__(self,aux=True):\n",
    "        self.minimos = None\n",
    "        self.maximos = None\n",
    "        \n",
    "    def fit(self,data):\n",
    "        self.minimos = np.nanmin(data, axis=(0,1))#, keepdims=True)\n",
    "        self.maximos = np.nanmax(data ,axis=(0,1))#, keepdims=True)\n",
    "    \n",
    "    def transform(self,data):\n",
    "        #normalize between 0 and 1 every statisctic\n",
    "        return (data-self.minimos) / (self.maximos-self.minimos)\n",
    "    \n",
    "    def inverse_transform(self,data):\n",
    "        return data*(self.maximos-self.minimos) + self.minimos\n",
    "    \n",
    "scaler_model1 = MinMax()\n",
    "scaler_model1.fit(trainX1_cond)\n",
    "X_train1_cond = scaler_model1.transform(trainX1_cond)\n",
    "X_test1_cond = scaler_model1.transform(testX1_cond)\n",
    "\n",
    "scaler_model2 = MinMax()\n",
    "scaler_model2.fit(trainX2_cond)\n",
    "X_train2_cond = scaler_model2.transform(trainX2_cond)\n",
    "X_test2_cond = scaler_model2.transform(testX2_cond)\n",
    "\n",
    "X_train1_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimos en train:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Minimos en test:  [6.89655125e-08 2.74869110e-02 2.99625468e-02 1.12001868e-01\n",
      " 4.98162247e-03 2.49952114e-02            nan            nan\n",
      " 2.50000000e-01 8.71331507e-02            nan            nan\n",
      " 0.00000000e+00 5.81265886e-04 8.90017964e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimos en train: \", np.nanmin(X_train1_cond, axis=(0,1)))\n",
    "print(\"Minimos en test: \", np.nanmin(X_test1_cond, axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximos en train:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Maximos en test:  [0.25981294 0.34102142 0.58563536 0.93545451 0.74557729 0.70256368\n",
      "        nan        nan 0.91729421 0.85851963        nan        nan\n",
      " 0.04044388 0.24578276 0.37012987]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximos en train: \", np.nanmax(X_train2_cond, axis=(0,1)))\n",
    "print(\"Maximos en test: \", np.nanmax(X_test2_cond, axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mascara agregada\n"
     ]
    }
   ],
   "source": [
    "mask_value = -1.\n",
    "def nan_to_num(data,mask_value):\n",
    "    return np.asarray([[[mask_value if np.isnan(x) else x for x in timestep] for timestep in array] for array in data])\n",
    "\n",
    "X_train1_cond = nan_to_num(X_train1_cond,mask_value)\n",
    "X_test1_cond = nan_to_num(X_test1_cond,mask_value)\n",
    "X_train2_cond = nan_to_num(X_train2_cond,mask_value)\n",
    "X_test2_cond = nan_to_num(X_test2_cond,mask_value)\n",
    "print(\"Mascara agregada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#para el Y tambien...\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#o standar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler_model = MinMaxScaler()\n",
    "scaler_model = StandardScaler()\n",
    "scaler_model.fit(trainY1)\n",
    "y_train1 = scaler_model.transform(trainY1)\n",
    "y_test1 = scaler_model.transform(testY1)\n",
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características del modelo:\n",
    "* Predecir el máximo de ozono $O_3$ del día siguiente (del período de 24 horas).\n",
    "* Grano de predicción: Horas o día?\n",
    "* Cuanta información anterior utilizar? ..3 dias\n",
    "* Nulos? en $O_3$ o contaminantes?\n",
    "    * Borrar\n",
    "    * Mascara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "opt = 'adam'\n",
    "loss_utilizada = 'mse' #?\n",
    "nhidden = 64\n",
    "from attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_330 (InputLayer)          (None, 3, 15)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 3, 10)        160         input_330[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_17 (Recurr [(None, 10), (None,  840         time_distributed_6[0][0]         \n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "__________________________________________________________________________________________________\n",
      "dense_200 (Dense)               (None, 8)            88          recurrent_sequential_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_18 (Recurr (None, 3, 8)         848         dense_200[0][0]                  \n",
      "                                                                 recurrent_sequential_17[0][1]    \n",
      "                                                                 recurrent_sequential_17[0][2]    \n",
      "                                                                 dense_200[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,936\n",
      "Trainable params: 1,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/farizrahman4u/seq2seq\n",
    "import seq2seq\n",
    "from seq2seq.models import Seq2Seq\n",
    "from seq2seq.models import AttentionSeq2Seq\n",
    "\n",
    "\n",
    "model = Seq2Seq(input_dim=features, input_length=timesteps,hidden_dim=10, output_length=timesteps, output_dim=8)\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_5 (Masking)          (None, 2, 15)             0         \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 2, 64)             15360     \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 2, 64)             24768     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 48,449\n",
      "Trainable params: 48,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_6 (Masking)          (None, 2, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 2, 128)            10240     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 2, 64)             86400     \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 104,961\n",
      "Trainable params: 104,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from seq2seq.models import Seq2Seq,AttentionSeq2Seq\n",
    "\n",
    "timesteps = X_train1_cond.shape[1]\n",
    "features = X_train1_cond.shape[2] #todo excepto o3\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "def attention_multiply(vects):\n",
    "    encoder, attention = vects\n",
    "    return K.batch_dot(attention,encoder, axes=1)\n",
    "\n",
    "def modelo(tipo,dia=True):\n",
    "    regularization = 0.005\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=mask_value, input_shape=(timesteps, features)))\n",
    "\n",
    "    if tipo==\"sin atencion\":\n",
    "        model.add(GRU(nhidden,return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "        model.add(GRU(nhidden,return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "    elif tipo==\"atencion\":\n",
    "        model.add(Bidirectional(SimpleRNN(nhidden, return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization))))\n",
    "        model.add(AttentionDecoder(nhidden, nhidden,kernel_regularizer=keras.regularizers.l2(regularization))) #que son esos  (units, output_dim)\n",
    "    \n",
    "    elif tipo==\"sin atencion libreria\":\n",
    "        aux_model = Seq2Seq(input_dim=features, hidden_dim=nhidden, output_length=timesteps, output_dim=nhidden,depth=2)\n",
    "        #teacherforse=True\n",
    "        #aux_model = Model(inputs=model.inputs,outputs=aux_model(model.outputs))\n",
    "        \n",
    "        layer_aux =  GRU(nhidden, return_sequences=False)(aux_model.outputs)\n",
    "        layer_aux = Dense(1,activation='linear')(layer_aux) #1 prediccion?\n",
    "        \n",
    "        model = Model(inputs=aux_model.inputs,outputs=layer_aux)\n",
    "        model.compile(loss=loss_utilizada,optimizer=opt)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    elif tipo==\"atencion libreria\":\n",
    "        aux_model = AttentionSeq2Seq(input_dim=features,input_length=timesteps,hidden_dim=nhidden\n",
    "                                     ,output_length=timesteps,output_dim=nhidden,depth=2)\n",
    "        model = Sequential()\n",
    "        model.add(aux_model)\n",
    "    \n",
    "    if dia:\n",
    "        model.add(SimpleRNN(nhidden, return_sequences=False,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(regularization))) #1 prediccion?\n",
    "    else:\n",
    "        model.add(TimeDistributed(Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(regularization)))) #varias prediccions--a nivel de horario..\n",
    "        model.add(GlobalMaxPooling1D())\n",
    "    \n",
    "    model.compile(loss=loss_utilizada,optimizer=opt)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "modelo1 = modelo(\"sin atencion\",dia)\n",
    "modelo2 = modelo(\"atencion\",dia)\n",
    "#modelo3 = modelo(\"sin atencion libreria\",dia) #no soportan masking\n",
    "#modelo4 = modelo(\"atencion libreria\",dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "2931/2931 [==============================] - 16s 5ms/step - loss: 4795.9105 - val_loss: 2463.4797\n",
      "Epoch 2/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 3188.1914 - val_loss: 1612.2063\n",
      "Epoch 3/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 2267.3023 - val_loss: 1067.5342\n",
      "Epoch 4/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1634.1946 - val_loss: 743.1862\n",
      "Epoch 5/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1212.6078 - val_loss: 571.3133\n",
      "Epoch 6/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 950.7781 - val_loss: 499.9965\n",
      "Epoch 7/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 796.5459 - val_loss: 486.4146\n",
      "Epoch 8/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 712.0374 - val_loss: 501.9297\n",
      "Epoch 9/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 660.4086 - val_loss: 529.2709\n",
      "Epoch 10/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 640.6041 - val_loss: 555.0939\n",
      "Epoch 11/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 628.6702 - val_loss: 578.5522\n",
      "Epoch 12/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 625.5286 - val_loss: 594.6311\n",
      "Epoch 13/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 620.1993 - val_loss: 605.0368\n",
      "Epoch 14/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 621.3129 - val_loss: 608.1636\n",
      "Epoch 15/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 625.3954 - val_loss: 615.7319\n",
      "Epoch 16/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 622.8338 - val_loss: 617.9961\n",
      "Epoch 17/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 630.5630 - val_loss: 624.9653\n",
      "Epoch 18/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 618.2645 - val_loss: 621.6193\n",
      "Epoch 19/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 620.9180 - val_loss: 622.1449\n",
      "Epoch 20/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 627.5105 - val_loss: 621.5922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70e715cb38>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo1.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2932 samples, validate on 196 samples\n",
      "Epoch 1/20\n",
      "2932/2932 [==============================] - 8s 3ms/step - loss: 6156.4160 - val_loss: 3409.0167\n",
      "Epoch 2/20\n",
      "2932/2932 [==============================] - 3s 928us/step - loss: 4361.7839 - val_loss: 2580.3851\n",
      "Epoch 3/20\n",
      "2932/2932 [==============================] - 3s 918us/step - loss: 3547.3577 - val_loss: 2046.2837\n",
      "Epoch 4/20\n",
      "2932/2932 [==============================] - 3s 921us/step - loss: 2955.5634 - val_loss: 1637.4532\n",
      "Epoch 5/20\n",
      "2932/2932 [==============================] - 3s 915us/step - loss: 2460.3672 - val_loss: 1318.6476\n",
      "Epoch 6/20\n",
      "2932/2932 [==============================] - 3s 954us/step - loss: 2080.2032 - val_loss: 1070.3082\n",
      "Epoch 7/20\n",
      "2932/2932 [==============================] - 3s 928us/step - loss: 1751.3824 - val_loss: 880.0197\n",
      "Epoch 8/20\n",
      "2932/2932 [==============================] - 3s 963us/step - loss: 1496.1631 - val_loss: 738.9321\n",
      "Epoch 9/20\n",
      "2932/2932 [==============================] - 3s 956us/step - loss: 1272.8450 - val_loss: 635.7675\n",
      "Epoch 10/20\n",
      "2932/2932 [==============================] - 3s 912us/step - loss: 1126.1931 - val_loss: 566.7740\n",
      "Epoch 11/20\n",
      "2932/2932 [==============================] - 3s 905us/step - loss: 983.9844 - val_loss: 523.0552\n",
      "Epoch 12/20\n",
      "2932/2932 [==============================] - 3s 936us/step - loss: 883.5465 - val_loss: 499.0174\n",
      "Epoch 13/20\n",
      "2932/2932 [==============================] - 3s 900us/step - loss: 813.3539 - val_loss: 489.4695\n",
      "Epoch 14/20\n",
      "2932/2932 [==============================] - 3s 908us/step - loss: 762.6582 - val_loss: 490.2479\n",
      "Epoch 15/20\n",
      "2932/2932 [==============================] - 3s 902us/step - loss: 736.1057 - val_loss: 498.0404\n",
      "Epoch 16/20\n",
      "2932/2932 [==============================] - 3s 917us/step - loss: 707.6120 - val_loss: 509.6798\n",
      "Epoch 17/20\n",
      "2932/2932 [==============================] - 3s 903us/step - loss: 685.2843 - val_loss: 524.6585\n",
      "Epoch 18/20\n",
      "2932/2932 [==============================] - 3s 922us/step - loss: 663.5325 - val_loss: 538.5139\n",
      "Epoch 19/20\n",
      "2932/2932 [==============================] - 3s 913us/step - loss: 657.1665 - val_loss: 552.9461\n",
      "Epoch 20/20\n",
      "2932/2932 [==============================] - 3s 913us/step - loss: 646.7853 - val_loss: 565.1449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feeac7e9438>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2.fit(X_train1_cond, trainY1_cond, epochs=epochs, batch_size=batch_size, validation_data=(X_test1_cond, testY1_cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "2931/2931 [==============================] - 10s 3ms/step - loss: 5547.7214 - val_loss: 3281.8654\n",
      "Epoch 2/20\n",
      "2931/2931 [==============================] - 3s 920us/step - loss: 4409.8734 - val_loss: 2673.9456\n",
      "Epoch 3/20\n",
      "2931/2931 [==============================] - 3s 925us/step - loss: 3724.7958 - val_loss: 2181.2437\n",
      "Epoch 4/20\n",
      "2931/2931 [==============================] - 3s 917us/step - loss: 3147.9999 - val_loss: 1776.6224\n",
      "Epoch 5/20\n",
      "2931/2931 [==============================] - 3s 917us/step - loss: 2660.8413 - val_loss: 1447.3498\n",
      "Epoch 6/20\n",
      "2931/2931 [==============================] - 3s 912us/step - loss: 2250.8498 - val_loss: 1181.4483\n",
      "Epoch 7/20\n",
      "2931/2931 [==============================] - 3s 904us/step - loss: 1907.9772 - val_loss: 973.2219\n",
      "Epoch 8/20\n",
      "2931/2931 [==============================] - 3s 918us/step - loss: 1624.2174 - val_loss: 811.1032\n",
      "Epoch 9/20\n",
      "2931/2931 [==============================] - 3s 909us/step - loss: 1391.3212 - val_loss: 691.3513\n",
      "Epoch 10/20\n",
      "2931/2931 [==============================] - 3s 911us/step - loss: 1203.3298 - val_loss: 603.8236\n",
      "Epoch 11/20\n",
      "2931/2931 [==============================] - 3s 906us/step - loss: 1052.6061 - val_loss: 545.6197\n",
      "Epoch 12/20\n",
      "2931/2931 [==============================] - 3s 902us/step - loss: 934.2267 - val_loss: 508.6749\n",
      "Epoch 13/20\n",
      "2931/2931 [==============================] - 3s 910us/step - loss: 842.5270 - val_loss: 489.9399\n",
      "Epoch 14/20\n",
      "2931/2931 [==============================] - 3s 905us/step - loss: 773.0724 - val_loss: 483.9677\n",
      "Epoch 15/20\n",
      "2931/2931 [==============================] - 3s 913us/step - loss: 721.0745 - val_loss: 487.4383\n",
      "Epoch 16/20\n",
      "2931/2931 [==============================] - 3s 922us/step - loss: 682.9874 - val_loss: 497.3355\n",
      "Epoch 17/20\n",
      "2931/2931 [==============================] - 3s 907us/step - loss: 655.6138 - val_loss: 510.5886\n",
      "Epoch 18/20\n",
      "2931/2931 [==============================] - 3s 918us/step - loss: 636.3895 - val_loss: 525.7598\n",
      "Epoch 19/20\n",
      "2931/2931 [==============================] - 3s 923us/step - loss: 623.2174 - val_loss: 541.4706\n",
      "Epoch 20/20\n",
      "2931/2931 [==============================] - 3s 910us/step - loss: 614.4102 - val_loss: 555.7706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72a41b5208>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo3.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2344 samples, validate on 587 samples\n",
      "Epoch 1/35\n",
      "2344/2344 [==============================] - 18s 8ms/step - loss: 6325.8340 - val_loss: 3044.6481\n",
      "Epoch 2/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 5058.5314 - val_loss: 2528.5521\n",
      "Epoch 3/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 4419.0833 - val_loss: 2110.7708\n",
      "Epoch 4/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 3887.9318 - val_loss: 1758.1582\n",
      "Epoch 5/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 3410.2067 - val_loss: 1458.3951\n",
      "Epoch 6/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 2982.5870 - val_loss: 1207.8356\n",
      "Epoch 7/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 2618.1257 - val_loss: 998.6351\n",
      "Epoch 8/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 2308.1165 - val_loss: 827.6486\n",
      "Epoch 9/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 2023.8228 - val_loss: 688.6820\n",
      "Epoch 10/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 1788.2647 - val_loss: 579.8711\n",
      "Epoch 11/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 1589.2772 - val_loss: 496.4047\n",
      "Epoch 12/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 1407.6182 - val_loss: 434.7389\n",
      "Epoch 13/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 1254.2499 - val_loss: 392.6527\n",
      "Epoch 14/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 1136.2712 - val_loss: 366.2712\n",
      "Epoch 15/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 1033.8483 - val_loss: 352.8653\n",
      "Epoch 16/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 963.4240 - val_loss: 350.5089\n",
      "Epoch 17/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 882.1320 - val_loss: 356.5231\n",
      "Epoch 18/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 821.4700 - val_loss: 368.8206\n",
      "Epoch 19/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 786.1882 - val_loss: 385.5279\n",
      "Epoch 20/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 746.6950 - val_loss: 406.3012\n",
      "Epoch 21/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 731.2610 - val_loss: 428.0862\n",
      "Epoch 22/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 711.2988 - val_loss: 450.5500\n",
      "Epoch 23/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 697.2189 - val_loss: 472.4358\n",
      "Epoch 24/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 686.1521 - val_loss: 493.6366\n",
      "Epoch 25/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 691.9894 - val_loss: 514.6055\n",
      "Epoch 26/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 656.4512 - val_loss: 532.7395\n",
      "Epoch 27/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 658.6402 - val_loss: 550.2842\n",
      "Epoch 28/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 657.0736 - val_loss: 562.4722\n",
      "Epoch 29/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 656.8392 - val_loss: 575.2738\n",
      "Epoch 30/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 653.8896 - val_loss: 587.4609\n",
      "Epoch 31/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 643.4660 - val_loss: 597.1449\n",
      "Epoch 32/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 652.1967 - val_loss: 606.7565\n",
      "Epoch 33/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 648.9965 - val_loss: 612.3913\n",
      "Epoch 34/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 646.4532 - val_loss: 617.4526\n",
      "Epoch 35/35\n",
      "2344/2344 [==============================] - 4s 2ms/step - loss: 656.9175 - val_loss: 621.8060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72ac28a438>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo4.fit(X_train1, trainY1, epochs=35, batch_size=batch_size,validation_split=0.2)# validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seguir con modelo 3 y modelo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#ivnierno\n",
    "modelo1.fit(X_train2, trainY2, epochs=epochs, batch_size=batch_size, validation_data=(X_test2, testY2))\n",
    "modelo2.fit(X_train2, trainY2, epochs=epochs, batch_size=batch_size, validation_data=(X_test2, testY2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `rmse` not found.\n"
     ]
    }
   ],
   "source": [
    "## evaluación?\n",
    "rmse?\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse_evaluation(model,input_data,output_data):\n",
    "    predict = model.predict(input_data)\n",
    "    #recover data\n",
    "    predict = scaler_model.inverse_transform(predict)\n",
    "    output_data = scaler_model.inverse_transform(output_data)\n",
    "    print(\"RMSE del modelo en test: \",np.sqrt(mean_squared_error(output_data,predict)))\n",
    "    return \n",
    "\n",
    "def evaluar_modelo(modelito,data):\n",
    "    mse_test = modelito.evaluate(data[0],data[1])\n",
    "    print(\"RMSE del modelo en test: \",np.sqrt(mse_test))\n",
    "    return np.sqrt(mse_test)\n",
    "#if es hora.. max\n",
    "# si es por dia ya predice max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 433us/step\n",
      "RMSE del modelo en test:  23.4404439523934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.4404439523934"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo1,[X_test1,testY1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-efc2da9c2504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelo2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test1' is not defined"
     ]
    }
   ],
   "source": [
    "rmse_evaluation(modelo2,X_test1,y_test1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 622us/step\n",
      "RMSE del modelo en test:  31.925947610200936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.925947610200936"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2,[X_test1,testY1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 630us/step\n",
      "RMSE del modelo en test:  26.32290688251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.32290688251"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo4,[X_test1,testY1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenar 1 modelo por cada conjunto y promediar o entrenar juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_67 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_161 (GRU)                (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_68 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_163 (GRU)                (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "2931/2931 [==============================] - 17s 6ms/step - loss: 6155.9501 - val_loss: 3121.1954\n",
      "Epoch 2/20\n",
      "2931/2931 [==============================] - 1s 464us/step - loss: 4127.6794 - val_loss: 2406.3880\n",
      "Epoch 3/20\n",
      "2931/2931 [==============================] - 1s 491us/step - loss: 3381.1038 - val_loss: 1908.5063\n",
      "Epoch 4/20\n",
      "2931/2931 [==============================] - 1s 496us/step - loss: 2799.2026 - val_loss: 1524.8742\n",
      "Epoch 5/20\n",
      "2931/2931 [==============================] - 1s 491us/step - loss: 2348.0240 - val_loss: 1225.7524\n",
      "Epoch 6/20\n",
      "2931/2931 [==============================] - 1s 475us/step - loss: 1965.6158 - val_loss: 994.2796\n",
      "Epoch 7/20\n",
      "2931/2931 [==============================] - 1s 485us/step - loss: 1660.5214 - val_loss: 819.5310\n",
      "Epoch 8/20\n",
      "2931/2931 [==============================] - 1s 467us/step - loss: 1408.2978 - val_loss: 693.0456\n",
      "Epoch 9/20\n",
      "2931/2931 [==============================] - 1s 493us/step - loss: 1223.7780 - val_loss: 602.1245\n",
      "Epoch 10/20\n",
      "2931/2931 [==============================] - 1s 494us/step - loss: 1066.9246 - val_loss: 542.6654\n",
      "Epoch 11/20\n",
      "2931/2931 [==============================] - 1s 473us/step - loss: 940.0842 - val_loss: 506.6292\n",
      "Epoch 12/20\n",
      "2931/2931 [==============================] - 1s 471us/step - loss: 861.0803 - val_loss: 489.1559\n",
      "Epoch 13/20\n",
      "2931/2931 [==============================] - 1s 489us/step - loss: 795.9755 - val_loss: 484.7524\n",
      "Epoch 14/20\n",
      "2931/2931 [==============================] - 1s 487us/step - loss: 746.5207 - val_loss: 489.3890\n",
      "Epoch 15/20\n",
      "2931/2931 [==============================] - 1s 480us/step - loss: 710.6285 - val_loss: 499.9266\n",
      "Epoch 16/20\n",
      "2931/2931 [==============================] - 1s 485us/step - loss: 697.5514 - val_loss: 514.1757\n",
      "Epoch 17/20\n",
      "2931/2931 [==============================] - 1s 470us/step - loss: 665.0456 - val_loss: 529.3576\n",
      "Epoch 18/20\n",
      "2931/2931 [==============================] - 1s 468us/step - loss: 658.4426 - val_loss: 544.9145\n",
      "Epoch 19/20\n",
      "2931/2931 [==============================] - 2s 515us/step - loss: 658.9600 - val_loss: 557.4854\n",
      "Epoch 20/20\n",
      "2931/2931 [==============================] - 1s 481us/step - loss: 644.9292 - val_loss: 575.6131\n",
      "Train on 2401 samples, validate on 116 samples\n",
      "Epoch 1/20\n",
      "2401/2401 [==============================] - 17s 7ms/step - loss: 1065.1766 - val_loss: 87.9969\n",
      "Epoch 2/20\n",
      "2401/2401 [==============================] - 1s 500us/step - loss: 556.5330 - val_loss: 89.9402\n",
      "Epoch 3/20\n",
      "2401/2401 [==============================] - 1s 493us/step - loss: 484.2206 - val_loss: 117.3592\n",
      "Epoch 4/20\n",
      "2401/2401 [==============================] - 1s 466us/step - loss: 455.3539 - val_loss: 144.5604\n",
      "Epoch 5/20\n",
      "2401/2401 [==============================] - 1s 538us/step - loss: 445.3031 - val_loss: 167.0379\n",
      "Epoch 6/20\n",
      "2401/2401 [==============================] - 1s 469us/step - loss: 442.3183 - val_loss: 185.1103\n",
      "Epoch 7/20\n",
      "2401/2401 [==============================] - 1s 552us/step - loss: 440.8813 - val_loss: 196.4110\n",
      "Epoch 8/20\n",
      "2401/2401 [==============================] - 1s 519us/step - loss: 438.1845 - val_loss: 199.8050\n",
      "Epoch 9/20\n",
      "2401/2401 [==============================] - 1s 536us/step - loss: 422.3705 - val_loss: 156.8153\n",
      "Epoch 10/20\n",
      "2401/2401 [==============================] - 1s 498us/step - loss: 384.1452 - val_loss: 190.8879\n",
      "Epoch 11/20\n",
      "2401/2401 [==============================] - 1s 501us/step - loss: 370.6722 - val_loss: 260.6067\n",
      "Epoch 12/20\n",
      "2401/2401 [==============================] - 1s 523us/step - loss: 354.7258 - val_loss: 281.8870\n",
      "Epoch 13/20\n",
      "2401/2401 [==============================] - 1s 486us/step - loss: 349.7132 - val_loss: 315.4710\n",
      "Epoch 14/20\n",
      "2401/2401 [==============================] - 1s 485us/step - loss: 350.3784 - val_loss: 321.3379\n",
      "Epoch 15/20\n",
      "2401/2401 [==============================] - 1s 504us/step - loss: 342.5153 - val_loss: 376.1406\n",
      "Epoch 16/20\n",
      "2401/2401 [==============================] - 1s 483us/step - loss: 346.0013 - val_loss: 383.5395\n",
      "Epoch 17/20\n",
      "2401/2401 [==============================] - 1s 471us/step - loss: 340.7054 - val_loss: 391.4855\n",
      "Epoch 18/20\n",
      "2401/2401 [==============================] - 1s 501us/step - loss: 340.4693 - val_loss: 360.5254\n",
      "Epoch 19/20\n",
      "2401/2401 [==============================] - 1s 550us/step - loss: 339.5296 - val_loss: 426.8820\n",
      "Epoch 20/20\n",
      "2401/2401 [==============================] - 1s 525us/step - loss: 337.0061 - val_loss: 436.8329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93e20011d0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## mejor modelo atencion normal\n",
    "modelo_v = modelo(\"atencion\",dia)\n",
    "modelo_i = modelo(\"atencion\",dia)\n",
    "modelo_v.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))\n",
    "modelo_i.fit(X_train2, trainY2, epochs=epochs, batch_size=batch_size, validation_data=(X_test2, testY2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 371us/step\n",
      "RMSE del modelo en test:  23.991938999518787\n",
      "116/116 [==============================] - 0s 340us/step\n",
      "RMSE del modelo en test:  20.900546881842484\n",
      "En promedio este modelo da:  22.446242940680634\n"
     ]
    }
   ],
   "source": [
    "rmse_1 = evaluar_modelo(modelo_v,[X_test1,testY1])    \n",
    "rmse_2 = evaluar_modelo(modelo_i,[X_test2,testY2])    \n",
    "print(\"En promedio este modelo da: \",np.mean([rmse_1,rmse_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo en test:  22.86701676641055\n"
     ]
    }
   ],
   "source": [
    "## evaluación?\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predict1 = modelo_v.predict(X_test1)\n",
    "predict2 = modelo_i.predict(X_test2)\n",
    "\n",
    "print(\"RMSE del modelo en test: \",np.sqrt(mean_squared_error(y_new_test,np.concatenate((predict1,predict2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5330, 4, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack invierno y verano\n",
    "X_train_cond = np.concatenate((X_train1_cond,X_train2_cond))\n",
    "X_test_cond = np.concatenate((X_test1_cond,X_test2_cond))\n",
    "y_train_cond = np.concatenate((trainY1_cond,trainY2_cond))\n",
    "y_test_cond = np.concatenate((testY1_cond,testY2_cond))\n",
    "X_train_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_70 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_167 (GRU)                (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5332 samples, validate on 311 samples\n",
      "Epoch 1/30\n",
      "5332/5332 [==============================] - 20s 4ms/step - loss: 3231.5229 - val_loss: 1614.2138\n",
      "Epoch 2/30\n",
      "5332/5332 [==============================] - 2s 439us/step - loss: 2011.0821 - val_loss: 1204.3134\n",
      "Epoch 3/30\n",
      "5332/5332 [==============================] - 2s 446us/step - loss: 1604.7259 - val_loss: 1021.5790\n",
      "Epoch 4/30\n",
      "5332/5332 [==============================] - 2s 447us/step - loss: 1381.4656 - val_loss: 956.7702\n",
      "Epoch 5/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 1279.0124 - val_loss: 948.9930\n",
      "Epoch 6/30\n",
      "5332/5332 [==============================] - 2s 439us/step - loss: 1236.8386 - val_loss: 961.4927\n",
      "Epoch 7/30\n",
      "5332/5332 [==============================] - 2s 442us/step - loss: 943.4692 - val_loss: 750.2730\n",
      "Epoch 8/30\n",
      "5332/5332 [==============================] - 2s 435us/step - loss: 741.6348 - val_loss: 793.9720\n",
      "Epoch 9/30\n",
      "5332/5332 [==============================] - 2s 445us/step - loss: 675.7203 - val_loss: 844.4862\n",
      "Epoch 10/30\n",
      "5332/5332 [==============================] - 2s 434us/step - loss: 638.7575 - val_loss: 877.5254\n",
      "Epoch 11/30\n",
      "5332/5332 [==============================] - 2s 440us/step - loss: 585.7677 - val_loss: 329.0120\n",
      "Epoch 12/30\n",
      "5332/5332 [==============================] - 2s 436us/step - loss: 554.6878 - val_loss: 308.7417\n",
      "Epoch 13/30\n",
      "5332/5332 [==============================] - 2s 443us/step - loss: 538.6018 - val_loss: 359.2524\n",
      "Epoch 14/30\n",
      "5332/5332 [==============================] - 2s 437us/step - loss: 513.6801 - val_loss: 298.4245\n",
      "Epoch 15/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 461.3325 - val_loss: 262.1252\n",
      "Epoch 16/30\n",
      "5332/5332 [==============================] - 2s 437us/step - loss: 437.5478 - val_loss: 332.5225\n",
      "Epoch 17/30\n",
      "5332/5332 [==============================] - 2s 438us/step - loss: 429.6047 - val_loss: 286.2611\n",
      "Epoch 18/30\n",
      "5332/5332 [==============================] - 2s 435us/step - loss: 422.7401 - val_loss: 269.3060\n",
      "Epoch 19/30\n",
      "5332/5332 [==============================] - 2s 443us/step - loss: 427.6611 - val_loss: 283.0325\n",
      "Epoch 20/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 411.7659 - val_loss: 334.4499\n",
      "Epoch 21/30\n",
      "5332/5332 [==============================] - 2s 443us/step - loss: 410.3335 - val_loss: 316.4678\n",
      "Epoch 22/30\n",
      "5332/5332 [==============================] - 2s 440us/step - loss: 403.8675 - val_loss: 314.8837\n",
      "Epoch 23/30\n",
      "5332/5332 [==============================] - 2s 441us/step - loss: 402.9730 - val_loss: 273.2212\n",
      "Epoch 24/30\n",
      "5332/5332 [==============================] - 2s 445us/step - loss: 401.2417 - val_loss: 276.7344\n",
      "Epoch 25/30\n",
      "5332/5332 [==============================] - 2s 440us/step - loss: 395.2509 - val_loss: 284.7889\n",
      "Epoch 26/30\n",
      "5332/5332 [==============================] - 2s 439us/step - loss: 396.6369 - val_loss: 299.1025\n",
      "Epoch 27/30\n",
      "5332/5332 [==============================] - 2s 433us/step - loss: 390.9890 - val_loss: 292.2640\n",
      "Epoch 28/30\n",
      "5332/5332 [==============================] - 2s 433us/step - loss: 397.4213 - val_loss: 280.1842\n",
      "Epoch 29/30\n",
      "5332/5332 [==============================] - 2s 436us/step - loss: 389.6017 - val_loss: 293.4558\n",
      "Epoch 30/30\n",
      "5332/5332 [==============================] - 2s 444us/step - loss: 388.4626 - val_loss: 295.8303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93c824ca90>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2_both = modelo(\"atencion\",dia)\n",
    "modelo2_both.fit(X_new_train, y_new_train, epochs=25, batch_size=batch_size, validation_data=(X_new_test, y_new_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/311 [==============================] - 0s 344us/step\n",
      "RMSE del modelo en test:  17.199719013374132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.199719013374132"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2_both,[X_new_test,y_new_test])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados: Entrenar un mismo modelo en invierno y verano es mejor..\n",
    "### Conclusiones: Los patrones relacionados con la tarea asignada se repiten/son compartidos en ambos conjuntos\n",
    "\n",
    "## Mejorar\n",
    "---\n",
    "* seguir con atención\n",
    "* Probar predecir secuencia completa (horas)---otro archivo\n",
    "* juntar con independencia???\n",
    "* aumentar lag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60809</th>\n",
       "      <td>2017-08-31 19:00:00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.22</td>\n",
       "      <td>24.6867</td>\n",
       "      <td>57.9056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.499</td>\n",
       "      <td>62.5029</td>\n",
       "      <td>16.1848</td>\n",
       "      <td>1.266580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60810</th>\n",
       "      <td>2017-08-31 20:00:00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>111.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.79</td>\n",
       "      <td>46.8800</td>\n",
       "      <td>85.6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.815</td>\n",
       "      <td>66.0876</td>\n",
       "      <td>15.2838</td>\n",
       "      <td>0.807589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60811</th>\n",
       "      <td>2017-08-31 21:00:00</td>\n",
       "      <td>1.32</td>\n",
       "      <td>116.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.44</td>\n",
       "      <td>55.4550</td>\n",
       "      <td>90.8917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.223</td>\n",
       "      <td>71.3362</td>\n",
       "      <td>14.0254</td>\n",
       "      <td>0.161541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60812</th>\n",
       "      <td>2017-08-31 22:00:00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>153.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.11</td>\n",
       "      <td>98.7384</td>\n",
       "      <td>132.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.665</td>\n",
       "      <td>75.0015</td>\n",
       "      <td>13.2669</td>\n",
       "      <td>0.310322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60813</th>\n",
       "      <td>2017-08-31 23:00:00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>128.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>27.97</td>\n",
       "      <td>107.9670</td>\n",
       "      <td>135.9380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.886</td>\n",
       "      <td>79.0000</td>\n",
       "      <td>12.4667</td>\n",
       "      <td>0.878486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on    CO   PM10  PM25    NO2        NO       NOX  SO2  \\\n",
       "60809  2017-08-31 19:00:00  0.75   85.0  33.0  33.22   24.6867   57.9056  NaN   \n",
       "60810  2017-08-31 20:00:00  1.10  111.0  36.0  38.79   46.8800   85.6667  NaN   \n",
       "60811  2017-08-31 21:00:00  1.32  116.0  34.0  35.44   55.4550   90.8917  NaN   \n",
       "60812  2017-08-31 22:00:00  1.75  153.0  67.0  34.11   98.7384  132.8500  NaN   \n",
       "60813  2017-08-31 23:00:00  1.73  128.0  43.0  27.97  107.9670  135.9380  NaN   \n",
       "\n",
       "            WD       RH     TEMP        WS  HCNM  UVA  UVB   O3  \n",
       "60809  149.499  62.5029  16.1848  1.266580   NaN  0.0  0.0  3.0  \n",
       "60810  128.815  66.0876  15.2838  0.807589   NaN  0.0  0.0  1.0  \n",
       "60811  335.223  71.3362  14.0254  0.161541   NaN  0.0  0.0  1.0  \n",
       "60812  126.665  75.0015  13.2669  0.310322   NaN  0.0  0.0  1.0  \n",
       "60813  336.886  79.0000  12.4667  0.878486   NaN  0.0  0.0  1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_independencia_verano_train = df_independencia_verano[(df_independencia_verano[\"registered_on\"]<\"2017\")]\n",
    "df_independencia_invierno_train = df_independencia_invierno[(df_independencia_invierno[\"registered_on\"]<\"2017\")]\n",
    "df_independencia_verano_test = df_independencia_verano[df_independencia_verano[\"registered_on\"]>=\"2017\"]\n",
    "df_independencia_invierno_test = df_independencia_invierno[df_independencia_invierno[\"registered_on\"]>=\"2017\"]\n",
    "\n",
    "df_independencia_invierno.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: All-NaN slice encountered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays shapes\n",
      "Train verano (input):  (2924, 3, 15)\n",
      "Train invierno (input):  (2321, 3, 15)\n",
      "Train verano (output):  (2924, 24)\n",
      "Train invierno (output):  (2321, 24)\n"
     ]
    }
   ],
   "source": [
    "lag = 3\n",
    "dia=True\n",
    "trainX1_inde, trainY1_inde = create_sequences(df_independencia_verano_train, lag,dia)\n",
    "trainX2_inde, trainY2_inde = create_sequences(df_independencia_invierno_train, lag,dia)\n",
    "\n",
    "testX1_inde, testY1_inde = create_sequences(df_independencia_verano_test, lag,dia)\n",
    "testX2_inde, testY2_inde = create_sequences(df_independencia_invierno_test, lag,dia)\n",
    "\n",
    "print(\"All arrays shapes\")\n",
    "print(\"Train verano (input): \",trainX1_inde.shape)\n",
    "print(\"Train invierno (input): \",trainX2_inde.shape)\n",
    "print(\"Train verano (output): \",trainY1_inde.shape)\n",
    "print(\"Train invierno (output): \",trainY2_inde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximo calculado\n"
     ]
    }
   ],
   "source": [
    "#o predecir el maximo en etiqueta...\n",
    "trainY1_inde = np.nanmax(trainY1_inde,axis=1)\n",
    "trainY2_inde = np.nanmax(trainY2_inde,axis=1)\n",
    "testY1_inde =  np.nanmax(testY1_inde,axis=1)\n",
    "testY2_inde =  np.nanmax(testY2_inde,axis=1)\n",
    "print(\"Maximo calculado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: All-NaN slice encountered\n",
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: All-NaN slice encountered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2924, 3, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_model1 = MinMax()\n",
    "scaler_model1.fit(trainX1_inde)\n",
    "X_train1_inde = scaler_model1.transform(trainX1_inde)\n",
    "X_test1_inde = scaler_model1.transform(testX1_inde)\n",
    "\n",
    "scaler_model2 = MinMax()\n",
    "scaler_model2.fit(trainX2_inde)\n",
    "X_train2_inde = scaler_model2.transform(trainX2_inde)\n",
    "X_test2_inde = scaler_model2.transform(testX2_inde)\n",
    "\n",
    "X_train1_inde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mascara agregada\n"
     ]
    }
   ],
   "source": [
    "mask_value = -1.\n",
    "def nan_to_num(data,mask_value):\n",
    "    return np.asarray([[[mask_value if np.isnan(x) else x for x in timestep] for timestep in array] for array in data])\n",
    "\n",
    "X_train1_inde = nan_to_num(X_train1_inde,mask_value)\n",
    "X_test1_inde = nan_to_num(X_test1_inde,mask_value)\n",
    "X_train2_inde = nan_to_num(X_train2_inde,mask_value)\n",
    "X_test2_inde = nan_to_num(X_test2_inde,mask_value)\n",
    "print(\"Mascara agregada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5245, 3, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack invierno y verano\n",
    "X_train_inde = np.concatenate((X_train1_inde,X_train2_inde))\n",
    "X_test_inde = np.concatenate((X_test1_inde,X_test2_inde))\n",
    "y_train_inde = np.concatenate((trainY1_inde,trainY2_inde))\n",
    "y_test_inde = np.concatenate((testY1_inde,testY2_inde))\n",
    "X_train_inde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_4 (Masking)          (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 3, 256)            110592    \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 128)            344832    \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 554,241\n",
      "Trainable params: 554,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5245 samples, validate on 316 samples\n",
      "Epoch 1/25\n",
      "5245/5245 [==============================] - 15s 3ms/step - loss: 1044.0357 - val_loss: 408.5102\n",
      "Epoch 2/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 548.6515 - val_loss: 377.1348\n",
      "Epoch 3/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 466.1213 - val_loss: 167.8922\n",
      "Epoch 4/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 440.1538 - val_loss: 183.9512\n",
      "Epoch 5/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 431.4508 - val_loss: 189.6843\n",
      "Epoch 6/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 305.6803 - val_loss: 170.3000\n",
      "Epoch 7/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 258.1239 - val_loss: 129.9853\n",
      "Epoch 8/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 247.9213 - val_loss: 133.8278\n",
      "Epoch 9/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 241.5158 - val_loss: 122.5158\n",
      "Epoch 10/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 239.6052 - val_loss: 118.6774\n",
      "Epoch 11/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 239.3916 - val_loss: 131.7583\n",
      "Epoch 12/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 236.5042 - val_loss: 117.3876\n",
      "Epoch 13/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 235.7642 - val_loss: 118.0647\n",
      "Epoch 14/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 230.4613 - val_loss: 115.1307\n",
      "Epoch 15/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 228.4679 - val_loss: 112.6013\n",
      "Epoch 16/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 233.0769 - val_loss: 116.0599\n",
      "Epoch 17/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 231.1563 - val_loss: 119.3459\n",
      "Epoch 18/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 231.6131 - val_loss: 121.4501\n",
      "Epoch 19/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 228.8514 - val_loss: 118.1875\n",
      "Epoch 20/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 225.7210 - val_loss: 117.9236\n",
      "Epoch 21/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 225.0025 - val_loss: 130.7796\n",
      "Epoch 22/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 222.5154 - val_loss: 120.2698\n",
      "Epoch 23/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 223.0116 - val_loss: 119.5595\n",
      "Epoch 24/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 224.9817 - val_loss: 121.9065\n",
      "Epoch 25/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 224.1168 - val_loss: 138.1090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1ea9ee470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2_both = modelo(\"atencion\",dia)\n",
    "modelo2_both.fit(X_train_inde, y_train_inde, epochs=25, batch_size=batch_size, validation_data=(X_test_inde, y_test_inde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316/316 [==============================] - 0s 466us/step\n",
      "RMSE del modelo en test:  11.75197838017345\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.75197838017345"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2_both,[X_test_inde,y_test_inde])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El promedio entre los dos es:  14.475848696773792\n"
     ]
    }
   ],
   "source": [
    "print(\"El promedio entre los dos es: \",np.mean([17.199719013374132,11.75197838017345]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntar condes e independencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10577, 3, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack invierno y verano\n",
    "X_train_all = np.concatenate((X_train_inde,X_train_cond))\n",
    "X_test_all = np.concatenate((X_test_inde,X_test_cond))\n",
    "y_train_all = np.concatenate((y_train_inde,y_train_cond))\n",
    "y_test_all = np.concatenate((y_test_inde,y_test_cond))\n",
    "X_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_4 (Masking)          (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 10577 samples, validate on 627 samples\n",
      "Epoch 1/25\n",
      "10577/10577 [==============================] - 21s 2ms/step - loss: 1836.8023 - val_loss: 824.5983\n",
      "Epoch 2/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 1055.6000 - val_loss: 536.3963\n",
      "Epoch 3/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 791.6493 - val_loss: 466.0765\n",
      "Epoch 4/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 712.6395 - val_loss: 348.2979\n",
      "Epoch 5/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 688.4302 - val_loss: 352.2051\n",
      "Epoch 6/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 467.7556 - val_loss: 325.8260\n",
      "Epoch 7/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 399.2603 - val_loss: 285.9639\n",
      "Epoch 8/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 375.7483 - val_loss: 285.6807\n",
      "Epoch 9/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 362.1368 - val_loss: 306.2890\n",
      "Epoch 10/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 353.6144 - val_loss: 252.7044\n",
      "Epoch 11/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 354.9438 - val_loss: 265.6144\n",
      "Epoch 12/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 344.8834 - val_loss: 271.0552\n",
      "Epoch 13/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 336.2311 - val_loss: 276.7141\n",
      "Epoch 14/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 337.6067 - val_loss: 268.2934\n",
      "Epoch 15/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 333.9095 - val_loss: 247.5246\n",
      "Epoch 16/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 331.8456 - val_loss: 237.5281\n",
      "Epoch 17/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 333.2463 - val_loss: 230.5449\n",
      "Epoch 18/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 329.0784 - val_loss: 244.2795\n",
      "Epoch 19/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 322.4881 - val_loss: 227.6662\n",
      "Epoch 20/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 330.9943 - val_loss: 229.3148\n",
      "Epoch 21/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 324.8956 - val_loss: 219.3554\n",
      "Epoch 22/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 324.6380 - val_loss: 220.7239\n",
      "Epoch 23/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 320.5233 - val_loss: 226.8047\n",
      "Epoch 24/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 317.5008 - val_loss: 235.9300\n",
      "Epoch 25/25\n",
      "10577/10577 [==============================] - 15s 1ms/step - loss: 322.2757 - val_loss: 223.2540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5fbc71deb8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2_both_comunas = modelo(\"atencion\",dia)\n",
    "modelo2_both_comunas.fit(X_train_all,y_train_all,epochs=25,batch_size=batch_size,validation_data=(X_test_all,y_test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627/627 [==============================] - 0s 456us/step\n",
      "RMSE del modelo en test:  14.941687368600762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.941687368600762"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2_both_comunas,[X_test_all,y_test_all])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Ozono en comunas son distintas...\n",
    "---\n",
    "Separar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
