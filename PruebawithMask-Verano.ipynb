{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIIC - predecir ozono atmosferico\n",
    "---\n",
    "**Obj:** predecir el ozono atmosférico $O_3$ máximo del dia siguiente, utilizando la información de químicos de los dias anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras,gc,time\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-11-01 01:00:00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-11-01 02:00:00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-11-01 03:00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-11-01 04:00:00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-11-01 05:00:00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         registered_on   CO   PM10  PM25  NO2  NO  NOX  SO2  WD  RH  TEMP  WS  \\\n",
       "0  1997-11-01 01:00:00  2.7   63.0   NaN  NaN NaN  NaN  6.0 NaN NaN   NaN NaN   \n",
       "1  1997-11-01 02:00:00  2.6   54.0   NaN  NaN NaN  NaN  6.0 NaN NaN   NaN NaN   \n",
       "2  1997-11-01 03:00:00  2.2   53.0   NaN  NaN NaN  NaN  5.0 NaN NaN   NaN NaN   \n",
       "3  1997-11-01 04:00:00  2.5   65.0   NaN  NaN NaN  NaN  5.0 NaN NaN   NaN NaN   \n",
       "4  1997-11-01 05:00:00  2.3  118.0   NaN  NaN NaN  NaN  8.0 NaN NaN   NaN NaN   \n",
       "\n",
       "   HCNM  UVA  UVB   O3  \n",
       "0   NaN  NaN  NaN  1.0  \n",
       "1   NaN  NaN  NaN  1.0  \n",
       "2   NaN  NaN  NaN  1.0  \n",
       "3   NaN  NaN  NaN  1.0  \n",
       "4   NaN  NaN  NaN  1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = \"../proyecto/datasets/\"\n",
    "df_independencia_verano = pd.read_csv(folder+\"dump-Independencia_2018-04-12_230000-verano.csv\")\n",
    "df_independencia_invierno = pd.read_csv(folder+\"dump-Independencia_2018-04-12_230000-invierno.csv\")\n",
    "\n",
    "df_condes_verano = pd.read_csv(folder+\"dump-Las_Condes_2018-04-12_230000-verano.csv\")\n",
    "df_condes_invierno = pd.read_csv(folder+\"dump-Las_Condes_2018-04-12_230000-invierno.csv\")\n",
    "\n",
    "df_independencia_verano.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69390</th>\n",
       "      <td>2016-12-31 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553417</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0400</td>\n",
       "      <td>3.2450</td>\n",
       "      <td>10.28500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.8333</td>\n",
       "      <td>26.6333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69391</th>\n",
       "      <td>2016-12-31 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467584</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.4825</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>7.23250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.3333</td>\n",
       "      <td>26.3167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.9725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69392</th>\n",
       "      <td>2016-12-31 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>16.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.4925</td>\n",
       "      <td>2.9975</td>\n",
       "      <td>6.49000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.3333</td>\n",
       "      <td>26.0583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.3033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69393</th>\n",
       "      <td>2016-12-31 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.9050</td>\n",
       "      <td>3.4100</td>\n",
       "      <td>7.31500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.3333</td>\n",
       "      <td>25.1417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.9808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69394</th>\n",
       "      <td>2016-12-31 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.450417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.6275</td>\n",
       "      <td>3.1625</td>\n",
       "      <td>9.79001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.8333</td>\n",
       "      <td>24.1750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on  CH4        CO  PM10  PM25     NO2      NO  \\\n",
       "69390  2016-12-31 14:00:00  NaN  0.553417  53.0  24.0  7.0400  3.2450   \n",
       "69391  2016-12-31 15:00:00  NaN  0.467584  22.0  21.0  4.4825  2.7500   \n",
       "69392  2016-12-31 16:00:00  NaN  0.459000  16.5  13.0  3.4925  2.9975   \n",
       "69393  2016-12-31 17:00:00  NaN  0.459000  15.0  14.0  3.9050  3.4100   \n",
       "69394  2016-12-31 18:00:00  NaN  0.450417   NaN   NaN  6.6275  3.1625   \n",
       "\n",
       "            NOX  SO2  WD       RH     TEMP  WS  HCNM  UVA  UVB       O3  \n",
       "69390  10.28500  NaN NaN  41.8333  26.6333 NaN   NaN  NaN  NaN  72.5233  \n",
       "69391   7.23250  NaN NaN  39.3333  26.3167 NaN   NaN  NaN  NaN  58.9725  \n",
       "69392   6.49000  NaN NaN  37.3333  26.0583 NaN   NaN  NaN  NaN  50.3033  \n",
       "69393   7.31500  NaN NaN  36.3333  25.1417 NaN   NaN  NaN  NaN  42.9808  \n",
       "69394   9.79001  NaN NaN  38.8333  24.1750 NaN   NaN  NaN  NaN      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ultimo año como test\n",
    "df_condes_verano_train = df_condes_verano[(df_condes_verano[\"registered_on\"]<\"2017\")]\n",
    "df_condes_invierno_train = df_condes_invierno[(df_condes_invierno[\"registered_on\"]<\"2017\")]\n",
    "df_condes_verano_test = df_condes_verano[df_condes_verano[\"registered_on\"]>=\"2017\"]\n",
    "df_condes_invierno_test = df_condes_invierno[df_condes_invierno[\"registered_on\"]>=\"2017\"]\n",
    "\n",
    "df_condes_verano_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69395</th>\n",
       "      <td>2017-01-03 13:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.834697</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69396</th>\n",
       "      <td>2017-01-03 14:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.715235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69397</th>\n",
       "      <td>2017-01-03 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836667</td>\n",
       "      <td>13.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.2575</td>\n",
       "      <td>1.7600</td>\n",
       "      <td>12.0175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.9167</td>\n",
       "      <td>28.8167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.537322</td>\n",
       "      <td>73.6176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69398</th>\n",
       "      <td>2017-01-03 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.768001</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.8350</td>\n",
       "      <td>2.5025</td>\n",
       "      <td>13.3375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2500</td>\n",
       "      <td>28.2917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.778006</td>\n",
       "      <td>57.6258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69399</th>\n",
       "      <td>2017-01-03 17:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5775</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>14.1625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>27.4250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.862870</td>\n",
       "      <td>51.9867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on  CH4        CO  PM10  PM25      NO2      NO  \\\n",
       "69395  2017-01-03 13:00:00  NaN       NaN   NaN   NaN      NaN     NaN   \n",
       "69396  2017-01-03 14:00:00  NaN       NaN  19.5  21.0      NaN     NaN   \n",
       "69397  2017-01-03 15:00:00  NaN  0.836667  13.5  18.0  10.2575  1.7600   \n",
       "69398  2017-01-03 16:00:00  NaN  0.768001  19.5   2.0  10.8350  2.5025   \n",
       "69399  2017-01-03 17:00:00  NaN  0.793750  72.0  10.0  11.5775  2.5850   \n",
       "\n",
       "           NOX  SO2  WD       RH     TEMP  WS  HCNM  UVA        UVB       O3  \n",
       "69395      NaN  NaN NaN      NaN      NaN NaN   NaN  0.0  28.834697      NaN  \n",
       "69396      NaN  NaN NaN      NaN      NaN NaN   NaN  0.0  24.715235      NaN  \n",
       "69397  12.0175  NaN NaN  14.9167  28.8167 NaN   NaN  0.0  24.537322  73.6176  \n",
       "69398  13.3375  NaN NaN  12.2500  28.2917 NaN   NaN  0.0  17.778006  57.6258  \n",
       "69399  14.1625  NaN NaN  14.5000  27.4250 NaN   NaN  0.0   9.862870  51.9867  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_condes_verano_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [registered_on, CH4, CO, PM10, PM25, NO2, NO, NOX, SO2, WD, RH, TEMP, WS, HCNM, UVA, UVB, O3]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_condes_verano.dropna(how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si elimino todas las que tengan al menos un null se eliminan todos los registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows_to_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cf4d455d21bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_condes_verano_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrows_to_use\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"O3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(how=\"all\",O3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rows_to_use' is not defined"
     ]
    }
   ],
   "source": [
    "df_condes_verano_train.loc[:,rows_to_use].dropna(subset=[\"O3\"])#(how=\"all\",O3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRe PRocesarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## representacion\n",
    "rows_to_use = [\"CO\",\"PM10\",\"PM25\",\"NO2\",\"NO\",\"NOX\",\"SO2\",\"WD\",\"RH\",\"TEMP\",\"WS\",\"HCNM\",\"UVA\",\"UVB\",\"O3\"]\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def estadisticos(timesteps):\n",
    "    a_utilizar = [np.nanmax]#,np.nanmin,np.nanstd,np.nanmean]\n",
    "    return np.concatenate([ function(timesteps,axis=0) for function in a_utilizar])\n",
    "\n",
    "def create_sequences(dataframe,lag=1,dia=True):\n",
    "    #preprocesamiento asumiendo dataset es una secuencia\n",
    "    timestep = dataframe.loc[:,\"registered_on\"].values\n",
    "    \n",
    "    indices_orden = []\n",
    "    diax = timestep[0].split(\"-\")[-1].split(\" \")[0]\n",
    "    aux_indices1 = 0\n",
    "    aux_indices2 = 0 \n",
    "    for dato in timestep[1:]:\n",
    "        nuevo_dia = dato.split(\"-\")[-1].split(\" \")[0]\n",
    "        aux_indices2+=1\n",
    "        if diax != nuevo_dia:\n",
    "            diax = nuevo_dia\n",
    "            #if aux_indices2-aux_indices1==24:\n",
    "            #    aux_indices2-=1\n",
    "            indices_orden.append([aux_indices1,aux_indices2])\n",
    "            aux_indices1 = aux_indices2\n",
    "    indices_orden.append([aux_indices1,aux_indices2+1])\n",
    "    data = dataframe.loc[:,rows_to_use].values\n",
    "    data = np.asarray([data[init:finit] for init,finit in indices_orden])\n",
    "    \n",
    "    horas = 24\n",
    "    \n",
    "    dataX = []\n",
    "    dataY =[]\n",
    "    for t_plus_1 in range(lag,len(data)):\n",
    "        #se crea el Y (target)\n",
    "        predecir = data[t_plus_1][:,-1] #todas las ultimas columnas --sequence\n",
    "        dataY.append(predecir)\n",
    "        columnasX = [] #se crea el X (inputs) columnas para predecir Y\n",
    "        for i in np.arange(lag,0,-1): #para los valores anteriores al t_plus_1 durante un lag\n",
    "            columnasX.append( data[t_plus_1-i] )\n",
    "        dataX.append(columnasX)\n",
    "    \n",
    "    #mascara delete..\n",
    "    mask_delete = np.ones(len(dataY),dtype=bool)\n",
    "    if not dia: \n",
    "        for i,dato in enumerate(dataY):\n",
    "            if np.any(np.isnan(dato)): #uno en sequencia---algun nulo\n",
    "                mask_delete[i] = False #eliminar de training\n",
    "    else:\n",
    "        for i,dato in enumerate(dataY):\n",
    "            if np.all(np.isnan(dato)): #todos en sequencia\n",
    "                mask_delete[i] = False #eliminar de training\n",
    "        \n",
    "    if dia: #calcular estadisticos\n",
    "        dataX = [[ estadisticos(timestep) for timestep in datito] for datito in dataX] \n",
    "    else:\n",
    "        aux = [ np.concatenate(datito) for datito in dataX] #junta los lag..\n",
    "        #pad\n",
    "        mask = np.full(len(rows_to_use) , -1.)\n",
    "        dataX = pad_sequences(aux, maxlen=lag*horas, dtype='float32', padding='pre', value=mask) #rellena \n",
    "    dataY = pad_sequences(dataY, maxlen=horas, dtype='object', padding='post', value=np.nan) #rellena \n",
    "    return np.array(dataX)[mask_delete],np.array(dataY)[mask_delete]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays shapes\n",
      "Train verano (input):  (950, 48, 15)\n",
      "Train invierno (input):  (967, 48, 15)\n",
      "Train verano (output):  (950, 24)\n",
      "Train invierno (output):  (967, 24)\n"
     ]
    }
   ],
   "source": [
    "lag = 2\n",
    "dia=False\n",
    "trainX1_cond, trainY1_cond = create_sequences(df_condes_verano_train, lag,dia)\n",
    "trainX2_cond, trainY2_cond = create_sequences(df_condes_invierno_train, lag,dia)\n",
    "\n",
    "testX1_cond, testY1_cond = create_sequences(df_condes_verano_test, lag,dia)\n",
    "testX2_cond, testY2_cond = create_sequences(df_condes_invierno_test, lag,dia)\n",
    "\n",
    "print(\"All arrays shapes\")\n",
    "print(\"Train verano (input): \",trainX1_cond.shape)\n",
    "print(\"Train invierno (input): \",trainX2_cond.shape)\n",
    "print(\"Train verano (output): \",trainY1_cond.shape)\n",
    "print(\"Train invierno (output): \",trainY2_cond.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.,  -1.,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX1_cond[0,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximo calculado\n"
     ]
    }
   ],
   "source": [
    "#o predecir el maximo en etiqueta...\n",
    "trainY1_cond = np.nanmax(trainY1_cond,axis=1)\n",
    "trainY2_cond = np.nanmax(trainY2_cond,axis=1)\n",
    "testY1_cond =  np.nanmax(testY1_cond,axis=1)\n",
    "testY2_cond =  np.nanmax(testY2_cond,axis=1)\n",
    "print(\"Maximo calculado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trid_to_2d(array,backward=False):\n",
    "    if backward:\n",
    "        return array.reshape(array.shape[0]/lag, lag ,array.shape[-1])\n",
    "    else:\n",
    "        return array.reshape((np.prod(array.shape[:2]), array.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-355a8517d883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrid_to_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrid_to_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "trid_to_2d(trid_to_2d(trainX),backward=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalar datos y transformar para entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2931, 3, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculo de estadisticos (\"fit\") MinMaxScaler\n",
    "class MinMax(object):\n",
    "    def __init__(self,aux=True):\n",
    "        self.minimos = None\n",
    "        self.maximos = None\n",
    "        \n",
    "    def fit(self,data):\n",
    "        self.minimos = np.nanmin(data, axis=(0,1))#, keepdims=True)\n",
    "        self.maximos = np.nanmax(data ,axis=(0,1))#, keepdims=True)\n",
    "    \n",
    "    def transform(self,data):\n",
    "        #normalize between 0 and 1 every statisctic\n",
    "        return (data-self.minimos) / (self.maximos-self.minimos)\n",
    "    \n",
    "    def inverse_transform(self,data):\n",
    "        return data*(self.maximos-self.minimos) + self.minimos\n",
    "    \n",
    "scaler_model1 = MinMax()\n",
    "scaler_model1.fit(trainX1_cond)\n",
    "X_train1_cond = scaler_model1.transform(trainX1_cond)\n",
    "X_test1_cond = scaler_model1.transform(testX1_cond)\n",
    "\n",
    "scaler_model2 = MinMax()\n",
    "scaler_model2.fit(trainX2_cond)\n",
    "X_train2_cond = scaler_model2.transform(trainX2_cond)\n",
    "X_test2_cond = scaler_model2.transform(testX2_cond)\n",
    "\n",
    "X_train1_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimos en train:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Minimos en test:  [6.89655125e-08 2.74869110e-02 2.99625468e-02 1.12001868e-01\n",
      " 4.98162247e-03 2.49952114e-02            nan            nan\n",
      " 2.50000000e-01 8.71331507e-02            nan            nan\n",
      " 0.00000000e+00 5.81265886e-04 8.90017964e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimos en train: \", np.nanmin(X_train1_cond, axis=(0,1)))\n",
    "print(\"Minimos en test: \", np.nanmin(X_test1_cond, axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximos en train:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Maximos en test:  [0.25981294 0.34102142 0.58563536 0.93545451 0.74557729 0.70256368\n",
      "        nan        nan 0.91729421 0.85851963        nan        nan\n",
      " 0.04044388 0.24578276 0.37012987]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: All-NaN slice encountered\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximos en train: \", np.nanmax(X_train2_cond, axis=(0,1)))\n",
    "print(\"Maximos en test: \", np.nanmax(X_test2_cond, axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mascara agregada\n"
     ]
    }
   ],
   "source": [
    "mask_value = -1.\n",
    "def nan_to_num(data,mask_value):\n",
    "    return np.asarray([[[mask_value if np.isnan(x) else x for x in timestep] for timestep in array] for array in data])\n",
    "\n",
    "X_train1_cond = nan_to_num(X_train1_cond,mask_value)\n",
    "X_test1_cond = nan_to_num(X_test1_cond,mask_value)\n",
    "X_train2_cond = nan_to_num(X_train2_cond,mask_value)\n",
    "X_test2_cond = nan_to_num(X_test2_cond,mask_value)\n",
    "print(\"Mascara agregada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#para el Y tambien...\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#o standar\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler_model = MinMaxScaler()\n",
    "scaler_model = StandardScaler()\n",
    "scaler_model.fit(trainY1)\n",
    "y_train1 = scaler_model.transform(trainY1)\n",
    "y_test1 = scaler_model.transform(testY1)\n",
    "y_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características del modelo:\n",
    "* Predecir el máximo de ozono $O_3$ del día siguiente (del período de 24 horas).\n",
    "* Grano de predicción: Horas o día?\n",
    "* Cuanta información anterior utilizar? ..3 dias\n",
    "* Nulos? en $O_3$ o contaminantes?\n",
    "    * Borrar\n",
    "    * Mascara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "opt = 'adam'\n",
    "loss_utilizada = 'mse' #?\n",
    "nhidden = 64\n",
    "from attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_330 (InputLayer)          (None, 3, 15)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 3, 10)        160         input_330[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "private__optional_input_place_h (2,)                 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_17 (Recurr [(None, 10), (None,  840         time_distributed_6[0][0]         \n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "                                                                 private__optional_input_place_hol\n",
      "__________________________________________________________________________________________________\n",
      "dense_200 (Dense)               (None, 8)            88          recurrent_sequential_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "recurrent_sequential_18 (Recurr (None, 3, 8)         848         dense_200[0][0]                  \n",
      "                                                                 recurrent_sequential_17[0][1]    \n",
      "                                                                 recurrent_sequential_17[0][2]    \n",
      "                                                                 dense_200[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,936\n",
      "Trainable params: 1,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/farizrahman4u/seq2seq\n",
    "import seq2seq\n",
    "from seq2seq.models import Seq2Seq\n",
    "from seq2seq.models import AttentionSeq2Seq\n",
    "\n",
    "\n",
    "model = Seq2Seq(input_dim=features, input_length=timesteps,hidden_dim=10, output_length=timesteps, output_dim=8)\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_23 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "gru_52 (GRU)                 (None, 3, 64)             15360     \n",
      "_________________________________________________________________\n",
      "gru_53 (GRU)                 (None, 3, 64)             24768     \n",
      "_________________________________________________________________\n",
      "gru_54 (GRU)                 (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 64,961\n",
      "Trainable params: 64,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_24 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_56 (GRU)                 (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from seq2seq.models import Seq2Seq,AttentionSeq2Seq\n",
    "\n",
    "timesteps = X_train1_cond.shape[1]\n",
    "features = X_train1_cond.shape[2] #todo excepto o3\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "def attention_multiply(vects):\n",
    "    encoder, attention = vects\n",
    "    return K.batch_dot(attention,encoder, axes=1)\n",
    "\n",
    "def modelo(tipo,dia=True):\n",
    "    regularization = 0.005\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=mask_value, input_shape=(timesteps, features)))\n",
    "\n",
    "    if tipo==\"sin atencion\":\n",
    "        model.add(GRU(nhidden,return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "        model.add(GRU(nhidden,return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "    elif tipo==\"atencion\":\n",
    "        model.add(Bidirectional(GRU(nhidden, return_sequences=True,kernel_regularizer=keras.regularizers.l2(regularization))))\n",
    "        model.add(AttentionDecoder(nhidden, nhidden,kernel_regularizer=keras.regularizers.l2(regularization))) #que son esos  (units, output_dim)\n",
    "    elif tipo==\"sin atencion libreria\":\n",
    "        aux_model = Seq2Seq(input_dim=features, hidden_dim=nhidden, output_length=timesteps, output_dim=nhidden,depth=2)\n",
    "        #teacherforse=True\n",
    "        #aux_model = Model(inputs=model.inputs,outputs=aux_model(model.outputs))\n",
    "        \n",
    "        layer_aux =  GRU(nhidden, return_sequences=False)(aux_model.outputs)\n",
    "        layer_aux = Dense(1,activation='linear')(layer_aux) #1 prediccion?\n",
    "        \n",
    "        model = Model(inputs=aux_model.inputs,outputs=layer_aux)\n",
    "        model.compile(loss=loss_utilizada,optimizer=opt)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    elif tipo==\"atencion libreria\":\n",
    "        aux_model = AttentionSeq2Seq(input_dim=features,input_length=timesteps,hidden_dim=nhidden\n",
    "                                     ,output_length=timesteps,output_dim=nhidden,depth=2)\n",
    "        model = Sequential()\n",
    "        model.add(aux_model)\n",
    "    \n",
    "    if dia:\n",
    "        model.add(GRU(nhidden, return_sequences=False,kernel_regularizer=keras.regularizers.l2(regularization)))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(regularization))) #1 prediccion?\n",
    "    else:\n",
    "        model.add(TimeDistributed(Dense(1,activation='linear',kernel_regularizer=keras.regularizers.l2(regularization)))) #varias prediccions--a nivel de horario..\n",
    "        model.add(GlobalMaxPooling1D())\n",
    "    \n",
    "    model.compile(loss=loss_utilizada,optimizer=opt)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "modelo1 = modelo(\"sin atencion\",dia)\n",
    "modelo2 = modelo(\"atencion\",dia)\n",
    "#modelo3 = modelo(\"sin atencion libreria\",dia) #no soportan masking\n",
    "#modelo4 = modelo(\"atencion libreria\",dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "2931/2931 [==============================] - 16s 5ms/step - loss: 4795.9105 - val_loss: 2463.4797\n",
      "Epoch 2/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 3188.1914 - val_loss: 1612.2063\n",
      "Epoch 3/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 2267.3023 - val_loss: 1067.5342\n",
      "Epoch 4/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1634.1946 - val_loss: 743.1862\n",
      "Epoch 5/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 1212.6078 - val_loss: 571.3133\n",
      "Epoch 6/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 950.7781 - val_loss: 499.9965\n",
      "Epoch 7/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 796.5459 - val_loss: 486.4146\n",
      "Epoch 8/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 712.0374 - val_loss: 501.9297\n",
      "Epoch 9/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 660.4086 - val_loss: 529.2709\n",
      "Epoch 10/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 640.6041 - val_loss: 555.0939\n",
      "Epoch 11/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 628.6702 - val_loss: 578.5522\n",
      "Epoch 12/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 625.5286 - val_loss: 594.6311\n",
      "Epoch 13/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 620.1993 - val_loss: 605.0368\n",
      "Epoch 14/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 621.3129 - val_loss: 608.1636\n",
      "Epoch 15/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 625.3954 - val_loss: 615.7319\n",
      "Epoch 16/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 622.8338 - val_loss: 617.9961\n",
      "Epoch 17/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 630.5630 - val_loss: 624.9653\n",
      "Epoch 18/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 618.2645 - val_loss: 621.6193\n",
      "Epoch 19/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 620.9180 - val_loss: 622.1449\n",
      "Epoch 20/20\n",
      "2931/2931 [==============================] - 3s 1ms/step - loss: 627.5105 - val_loss: 621.5922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f70e715cb38>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo1.fit(X_train1, trainY1, epochs=epochs, batch_size=batch_size, validation_data=(X_test1, testY1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2931 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "2931/2931 [==============================] - 17s 6ms/step - loss: 6161.6290 - val_loss: 3098.3341\n",
      "Epoch 2/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 4096.7679 - val_loss: 2385.5135\n",
      "Epoch 3/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 3355.7471 - val_loss: 1889.5621\n",
      "Epoch 4/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 2787.2295 - val_loss: 1508.9222\n",
      "Epoch 5/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 2334.8390 - val_loss: 1212.4170\n",
      "Epoch 6/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 1951.3426 - val_loss: 983.7923\n",
      "Epoch 7/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 1645.6302 - val_loss: 811.7584\n",
      "Epoch 8/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 1402.5986 - val_loss: 685.6913\n",
      "Epoch 9/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 1201.8439 - val_loss: 597.2507\n",
      "Epoch 10/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 1062.1093 - val_loss: 538.9951\n",
      "Epoch 11/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 946.6922 - val_loss: 504.1367\n",
      "Epoch 12/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 852.3884 - val_loss: 488.1970\n",
      "Epoch 13/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 789.0195 - val_loss: 484.8883\n",
      "Epoch 14/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 753.6716 - val_loss: 490.5177\n",
      "Epoch 15/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 703.0683 - val_loss: 501.5153\n",
      "Epoch 16/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 687.6609 - val_loss: 516.0278\n",
      "Epoch 17/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 676.2795 - val_loss: 530.5286\n",
      "Epoch 18/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 656.7630 - val_loss: 544.1057\n",
      "Epoch 19/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 652.0822 - val_loss: 559.5169\n",
      "Epoch 20/20\n",
      "2931/2931 [==============================] - 4s 1ms/step - loss: 601.3546 - val_loss: 530.3296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ef9b6f2e8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2.fit(X_train1_cond, trainY1_cond, epochs=epochs, batch_size=batch_size, validation_data=(X_test1_cond, testY1_cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `rmse` not found.\n"
     ]
    }
   ],
   "source": [
    "## evaluación?\n",
    "rmse?\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def rmse_evaluation(model,input_data,output_data):\n",
    "    predict = model.predict(input_data)\n",
    "    #recover data\n",
    "    predict = scaler_model.inverse_transform(predict)\n",
    "    output_data = scaler_model.inverse_transform(output_data)\n",
    "    print(\"RMSE del modelo en test: \",np.sqrt(mean_squared_error(output_data,predict)))\n",
    "    return \n",
    "\n",
    "def evaluar_modelo(modelito,data):\n",
    "    mse_test = modelito.evaluate(data[0],data[1])\n",
    "    print(\"RMSE del modelo en test: \",np.sqrt(mse_test))\n",
    "    return np.sqrt(mse_test)\n",
    "#if es hora.. max\n",
    "# si es por dia ya predice max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 560us/step\n",
      "RMSE del modelo en test:  23.028886840777837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.028886840777837"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2,[X_test1_cond,testY1_cond])       #evaluar en verano unicamente.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 630us/step\n",
      "RMSE del modelo en test:  26.32290688251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26.32290688251"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo4,[X_test1,testY1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejor Entrenar comunas por separado pero verano e invierno juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5332, 3, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack invierno y verano\n",
    "X_train_cond = np.concatenate((X_train1_cond,X_train2_cond))\n",
    "y_train_cond = np.concatenate((trainY1_cond,trainY2_cond))\n",
    "X_train_cond.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_25 (Masking)         (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_58 (GRU)                 (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5332 samples, validate on 195 samples\n",
      "Epoch 1/20\n",
      "5332/5332 [==============================] - 21s 4ms/step - loss: 3262.9709 - val_loss: 2543.6232\n",
      "Epoch 2/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 2032.7601 - val_loss: 1748.7152\n",
      "Epoch 3/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 1609.4739 - val_loss: 1269.2128\n",
      "Epoch 4/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 1394.2655 - val_loss: 982.6385\n",
      "Epoch 5/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 1283.2820 - val_loss: 819.1400\n",
      "Epoch 6/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 1138.0171 - val_loss: 719.2238\n",
      "Epoch 7/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 819.5434 - val_loss: 644.4569\n",
      "Epoch 8/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 713.1360 - val_loss: 625.1538\n",
      "Epoch 9/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 655.5095 - val_loss: 536.6953\n",
      "Epoch 10/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 626.7962 - val_loss: 512.0219\n",
      "Epoch 11/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 591.4483 - val_loss: 488.8958\n",
      "Epoch 12/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 557.4595 - val_loss: 486.5026\n",
      "Epoch 13/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 542.0283 - val_loss: 468.7723\n",
      "Epoch 14/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 541.6675 - val_loss: 469.6823\n",
      "Epoch 15/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 483.5067 - val_loss: 457.7841\n",
      "Epoch 16/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 441.2343 - val_loss: 428.6851\n",
      "Epoch 17/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 430.0663 - val_loss: 411.4638\n",
      "Epoch 18/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 427.4261 - val_loss: 411.5183\n",
      "Epoch 19/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 415.3164 - val_loss: 397.4968\n",
      "Epoch 20/20\n",
      "5332/5332 [==============================] - 8s 1ms/step - loss: 414.8565 - val_loss: 458.0697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ef6596630>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2_both_cond = modelo(\"atencion\",dia)\n",
    "modelo2_both_cond.fit(X_train_cond,y_train_cond,epochs=epochs,batch_size=batch_size,validation_data=(X_test1_cond,testY1_cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 0s 561us/step\n",
      "RMSE del modelo en test:  21.402563555754845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.402563555754845"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2_both_cond,[X_test1_cond,testY1_cond])       #evaluar en verano unicamente.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_on</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>SO2</th>\n",
       "      <th>WD</th>\n",
       "      <th>RH</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>WS</th>\n",
       "      <th>HCNM</th>\n",
       "      <th>UVA</th>\n",
       "      <th>UVB</th>\n",
       "      <th>O3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60809</th>\n",
       "      <td>2017-08-31 19:00:00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>85.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.22</td>\n",
       "      <td>24.6867</td>\n",
       "      <td>57.9056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.499</td>\n",
       "      <td>62.5029</td>\n",
       "      <td>16.1848</td>\n",
       "      <td>1.266580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60810</th>\n",
       "      <td>2017-08-31 20:00:00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>111.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>38.79</td>\n",
       "      <td>46.8800</td>\n",
       "      <td>85.6667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.815</td>\n",
       "      <td>66.0876</td>\n",
       "      <td>15.2838</td>\n",
       "      <td>0.807589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60811</th>\n",
       "      <td>2017-08-31 21:00:00</td>\n",
       "      <td>1.32</td>\n",
       "      <td>116.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.44</td>\n",
       "      <td>55.4550</td>\n",
       "      <td>90.8917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>335.223</td>\n",
       "      <td>71.3362</td>\n",
       "      <td>14.0254</td>\n",
       "      <td>0.161541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60812</th>\n",
       "      <td>2017-08-31 22:00:00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>153.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.11</td>\n",
       "      <td>98.7384</td>\n",
       "      <td>132.8500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.665</td>\n",
       "      <td>75.0015</td>\n",
       "      <td>13.2669</td>\n",
       "      <td>0.310322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60813</th>\n",
       "      <td>2017-08-31 23:00:00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>128.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>27.97</td>\n",
       "      <td>107.9670</td>\n",
       "      <td>135.9380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.886</td>\n",
       "      <td>79.0000</td>\n",
       "      <td>12.4667</td>\n",
       "      <td>0.878486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             registered_on    CO   PM10  PM25    NO2        NO       NOX  SO2  \\\n",
       "60809  2017-08-31 19:00:00  0.75   85.0  33.0  33.22   24.6867   57.9056  NaN   \n",
       "60810  2017-08-31 20:00:00  1.10  111.0  36.0  38.79   46.8800   85.6667  NaN   \n",
       "60811  2017-08-31 21:00:00  1.32  116.0  34.0  35.44   55.4550   90.8917  NaN   \n",
       "60812  2017-08-31 22:00:00  1.75  153.0  67.0  34.11   98.7384  132.8500  NaN   \n",
       "60813  2017-08-31 23:00:00  1.73  128.0  43.0  27.97  107.9670  135.9380  NaN   \n",
       "\n",
       "            WD       RH     TEMP        WS  HCNM  UVA  UVB   O3  \n",
       "60809  149.499  62.5029  16.1848  1.266580   NaN  0.0  0.0  3.0  \n",
       "60810  128.815  66.0876  15.2838  0.807589   NaN  0.0  0.0  1.0  \n",
       "60811  335.223  71.3362  14.0254  0.161541   NaN  0.0  0.0  1.0  \n",
       "60812  126.665  75.0015  13.2669  0.310322   NaN  0.0  0.0  1.0  \n",
       "60813  336.886  79.0000  12.4667  0.878486   NaN  0.0  0.0  1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_independencia_verano_train = df_independencia_verano[(df_independencia_verano[\"registered_on\"]<\"2017\")]\n",
    "df_independencia_invierno_train = df_independencia_invierno[(df_independencia_invierno[\"registered_on\"]<\"2017\")]\n",
    "df_independencia_verano_test = df_independencia_verano[df_independencia_verano[\"registered_on\"]>=\"2017\"]\n",
    "df_independencia_invierno_test = df_independencia_invierno[df_independencia_invierno[\"registered_on\"]>=\"2017\"]\n",
    "\n",
    "df_independencia_invierno.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:7: RuntimeWarning: All-NaN slice encountered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays shapes\n",
      "Train verano (input):  (2924, 3, 15)\n",
      "Train invierno (input):  (2321, 3, 15)\n",
      "Train verano (output):  (2924, 24)\n",
      "Train invierno (output):  (2321, 24)\n"
     ]
    }
   ],
   "source": [
    "lag = 3\n",
    "dia=True\n",
    "trainX1_inde, trainY1_inde = create_sequences(df_independencia_verano_train, lag,dia)\n",
    "trainX2_inde, trainY2_inde = create_sequences(df_independencia_invierno_train, lag,dia)\n",
    "\n",
    "testX1_inde, testY1_inde = create_sequences(df_independencia_verano_test, lag,dia)\n",
    "testX2_inde, testY2_inde = create_sequences(df_independencia_invierno_test, lag,dia)\n",
    "\n",
    "print(\"All arrays shapes\")\n",
    "print(\"Train verano (input): \",trainX1_inde.shape)\n",
    "print(\"Train invierno (input): \",trainX2_inde.shape)\n",
    "print(\"Train verano (output): \",trainY1_inde.shape)\n",
    "print(\"Train invierno (output): \",trainY2_inde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximo calculado\n"
     ]
    }
   ],
   "source": [
    "#o predecir el maximo en etiqueta...\n",
    "trainY1_inde = np.nanmax(trainY1_inde,axis=1)\n",
    "trainY2_inde = np.nanmax(trainY2_inde,axis=1)\n",
    "testY1_inde =  np.nanmax(testY1_inde,axis=1)\n",
    "testY2_inde =  np.nanmax(testY2_inde,axis=1)\n",
    "print(\"Maximo calculado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:8: RuntimeWarning: All-NaN slice encountered\n",
      "/home/casapanshop/anaconda2/envs/py3/lib/python3.5/site-packages/ipykernel/__main__.py:9: RuntimeWarning: All-NaN slice encountered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2924, 3, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_model1 = MinMax()\n",
    "scaler_model1.fit(trainX1_inde)\n",
    "X_train1_inde = scaler_model1.transform(trainX1_inde)\n",
    "X_test1_inde = scaler_model1.transform(testX1_inde)\n",
    "\n",
    "scaler_model2 = MinMax()\n",
    "scaler_model2.fit(trainX2_inde)\n",
    "X_train2_inde = scaler_model2.transform(trainX2_inde)\n",
    "X_test2_inde = scaler_model2.transform(testX2_inde)\n",
    "\n",
    "X_train1_inde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mascara agregada\n"
     ]
    }
   ],
   "source": [
    "mask_value = -1.\n",
    "def nan_to_num(data,mask_value):\n",
    "    return np.asarray([[[mask_value if np.isnan(x) else x for x in timestep] for timestep in array] for array in data])\n",
    "\n",
    "X_train1_inde = nan_to_num(X_train1_inde,mask_value)\n",
    "X_test1_inde = nan_to_num(X_test1_inde,mask_value)\n",
    "X_train2_inde = nan_to_num(X_train2_inde,mask_value)\n",
    "X_test2_inde = nan_to_num(X_test2_inde,mask_value)\n",
    "print(\"Mascara agregada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5245, 3, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack invierno y verano\n",
    "X_train_inde = np.concatenate((X_train1_inde,X_train2_inde))\n",
    "y_train_inde = np.concatenate((trainY1_inde,trainY2_inde))\n",
    "X_train_inde.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_5 (Masking)          (None, 3, 15)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 3, 128)            30720     \n",
      "_________________________________________________________________\n",
      "AttentionDecoder (AttentionD (None, 3, 64)             86400     \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 64)                24768     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 141,953\n",
      "Trainable params: 141,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5245 samples, validate on 210 samples\n",
      "Epoch 1/25\n",
      "5245/5245 [==============================] - 14s 3ms/step - loss: 1312.9559 - val_loss: 607.1034\n",
      "Epoch 2/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 696.2019 - val_loss: 353.5333\n",
      "Epoch 3/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 544.8584 - val_loss: 291.3649\n",
      "Epoch 4/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 473.5034 - val_loss: 264.4500\n",
      "Epoch 5/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 451.2389 - val_loss: 236.1659\n",
      "Epoch 6/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 370.9297 - val_loss: 217.8799\n",
      "Epoch 7/25\n",
      "5245/5245 [==============================] - 8s 1ms/step - loss: 286.9917 - val_loss: 199.7999\n",
      "Epoch 8/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 261.4553 - val_loss: 161.7706\n",
      "Epoch 9/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 255.5266 - val_loss: 161.2735\n",
      "Epoch 10/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 252.7335 - val_loss: 153.4234\n",
      "Epoch 11/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 244.7355 - val_loss: 144.0343\n",
      "Epoch 12/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 244.4505 - val_loss: 169.4589\n",
      "Epoch 13/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 244.7239 - val_loss: 140.8113\n",
      "Epoch 14/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 241.5938 - val_loss: 131.7284\n",
      "Epoch 15/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 239.9146 - val_loss: 132.0116\n",
      "Epoch 16/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 234.3931 - val_loss: 133.7178\n",
      "Epoch 17/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 240.6120 - val_loss: 134.7349\n",
      "Epoch 18/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 238.1662 - val_loss: 132.2764\n",
      "Epoch 19/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 233.6893 - val_loss: 125.2245\n",
      "Epoch 20/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 234.9056 - val_loss: 128.9193\n",
      "Epoch 21/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 230.6526 - val_loss: 128.0472\n",
      "Epoch 22/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 230.6481 - val_loss: 128.9179\n",
      "Epoch 23/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 230.4947 - val_loss: 128.9725\n",
      "Epoch 24/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 229.8663 - val_loss: 131.7165\n",
      "Epoch 25/25\n",
      "5245/5245 [==============================] - 7s 1ms/step - loss: 227.5748 - val_loss: 130.5438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f20c16ab390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2_both_inde = modelo(\"atencion\",dia)\n",
    "modelo2_both_inde.fit(X_train_inde, y_train_inde, epochs=25, batch_size=batch_size, validation_data=(X_test1_inde, testY1_inde))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 0s 466us/step\n",
      "RMSE del modelo en test:  11.425576062718035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.425576062718035"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluar_modelo(modelo2_both_inde,[X_test1_inde,testY1_inde])   ##solo verano  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El promedio entre los dos es:  15.921746103000096\n"
     ]
    }
   ],
   "source": [
    "print(\"El promedio entre los dos es: \",np.mean([20.417916143282156,11.425576062718035]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
